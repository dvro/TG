% !TEX encoding = ISO-8859-1
\chapter{Técnicas de Seleção de Protótipos}
% \label{ch:tecnicasdeselecaodeprototipos}

Neste capítulo, serão mostradas as técnicas de seleção de protótipos abordadas neste trabalho. Cada uma das sessões abaixo abordará uma técnica, será mostrado o conceito da técnica, assim como o pseudo-código e as caracterísicas de cada uma destas técnicas.

\section{ENN}

Edited Nearest Neighbor Rule\cite{enn:2011} é uma técnica de seleção de protótipos puramente seletiva proposta por Wilson em 1976. De uma forma geral, esta técnica foi projetada para funcionar como um filtro de ruídos, ela elimina pontos na região de fronteira, região de alta susceptibilidade a erros, e com isso elimina ruídos.\

Por atuar apenas na região de fronteira, esta técnica possui uma baixa capacidade de redução, deixando as instâncias que não se encontram na região de fronteira intactas, exceto pelos ruídos extremos.\

Uma desvantagem desta técnica é que ela possui uma baixa capacidade de redução de elementos, visto que ela não elimina redundância.

Segue abaixo o algoritmo da execução do ENN e, logo após, alguns comentários sobre este algoritmo.

\begin{algorithm}
\caption{ENN}
\label{alg:enn}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
\FORALL {instância $e_i$ da base de dados original}
\STATE Aplique o KNN sobre $e_i$
\IF {$e_i$ foi classificado erroneamente}
\STATE salve $e_i$ em $list$
\ENDIF
\ENDFOR
\STATE Remova da base de dados todos os elementos que estão em $list$
\end{algorithmic}
\end{algorithm}

O valor de K pode variar de acordo com o tamanho da base de dados, porém, tipicamente, utiliza-se o valor de K=3. Tipicamente, O valor de K é inversamente proporcional a quantidade de instâncias que serão eliminadas, ou seja, para que o filtro elimine todos os possíveis ruídos, deve-se utilizar K=1.

\begin{figure}
\label{fig:enn}
\includegraphics[scale=0.40]{imagens/enn.eps}
\caption{ENN aplicado com K=3}
\end{figure}

Na figura \ref{fig:enn} pode-se observar uma base de dados com duas classes, no primeiro gráfico da figura, pode-se observar a base de dados original, antes da aplicação do ENN. No segundo gráfico, foi aplicado o \ref{alg:enn} com K=3 sobre a base de dados, os pontos pretos representam pontos que foram classificados erroneamente com a aplicação do KNN, a região circulada engloba os K elementos mais próximos. Observa-se que o elemento 11 foi utilizado para eliminar 2 instâncias ruidosas, um próprio ruído poderia ser utilizado para eliminar outro ruído, apesar de ser improvável.

O mais interessante do caso acima é que, após a aplicação do ENN, as classes ficaram bem separadas pelos quadrantes pontilhados, mostrando a eficiência do ENN para a base de dados acima.

Uma vantagem do ENN é que ele independe da ordem que a base de dados foi apresentada, ou seja, o ENN aplicado a uma base de dados, com o mesmo valor de K, sempre terá o mesmo resultado.

Porém, o ENN também apresenta desvantagens, ele possui uma baixa capacidade de redução, pois elimina apenas ruídos, mantendo instâncias que são desnecessárias, que apresentam apenas redundância de informação. No caso da \ref{fig:enn}, a base poderia ser representada por 4 instâncias bem posicionadas ou, por se tratar de uma técnica seletiva, com 8 instâncias, porém, o ENN manteve 13 instâncias, eliminando apenas 3.

Pelas suas características, normalmente o ENN é utilizado como método de pré-processamento da base de dados, eliminando apenas instâncias que apresentam alta probabilidade de serem ruídos.


No caso de bases desbalanceadas, o ENN pode tratar todas as instâncias da base minoritária como ruídos, caso a base seja altamente desbalanceada (isto será demonstrado posteriormente com exemplos). Uma possível adaptação para o ENN em bases altamente desbalanceadas é eliminar apenas os elementos que sejam da base de dados marjoritária. O algoritmo adaptado está demonstrado em \ref{alg:enn_for_unbalanced_datasets}.

\begin{algorithm}
\caption{ENN}
\label{alg:enn_for_unbalanced_datasets}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\FORALL {instância $e_i$ da base de dados original}
		\STATE Aplique o KNN sobre $e_i$
		\IF {$e_i$ foi classificado erroneamente}
			\IF {$e_i$ for da classe marjoritária}
				\STATE salve $e_i$ em $list$
			\ENDIF
		\ENDIF
	\ENDFOR
	\STATE Remova da base de dados todos os elementos que estão em $list$
\end{algorithmic}
\end{algorithm}

Com este algoritmo, as instâncias da classe minoritária seria mantida, e a região delimitada por ela seria mais bem definida.

\section{CNN}

Condensed Nearest Neighbor \cite{cnn:1968} é uma técnica de seleção de protótipos puramente seletiva que tem como objetivo eliminar informação redundante. Diferentemente do ENN \cite{enn:2011}, o CNN não elimina instâncias nas regiões de fronteira, a técnica mantém estes elementos pois estes que "são importantes" para distinguir entre duas classes.

A ideia geral do CNN é encontrar o menor subconjunto da base de dados original que, utilizando o 1-NN, classifica todos os padrões da base de dados original corretamente. Fazendo isso, o algoritmo elimina os elementos mais afastados da região de indecisão, da fronteira de classificação.

O algoritmo do CNN será mostrado abaixo, e logo após, comentários a respeito do mesmo.

\begin{algorithm}
\caption{CNN}
\label{alg:cnn}
\begin{algorithmic}[1]
	\REQUIRE {$list$: uma lista}
	\STATE Escolha um elemento de cada classe $aleatoreamente$ e coloque-os em $list$
	\FORALL {instância $e_i$ da base de dados original}
		\STATE $KNN(e_i,list)$
		\IF {$e_i$ foi classificado erroneamente}
			\STATE salve $e_i$ em $list$
		\ENDIF
	\ENDFOR
	\RETURN $list$, os protótipos
\end{algorithmic}
\end{algorithm}

Podemos observar que este algoritmo possui uma abordagem diferente do ENN, por exemplo, pois ele começa com um conjunto mínimo de instâncias (uma de cada classe) e depois adiciona instâncias conforme a necessidade de mantê-las para que todos os elementos da base de dados original sejam classificados corretamente.

Uma coisa que pode-se observar no algoritmo, é a palavra $aleatoriamente$, o que significa que o CNN aplicado numa mesma base de dados com um mesmo valor de K para o KNN, nem sempre resulta nos mesmos protótipos. O primeiro fato para que isso ocorra é a seleção aleatória dos protótipos iniciais. Existem algumas adaptações para o CNN, onde os protótipos iniciais são escolhidos utilizando técnicas como o SGP\cite{fayed:sgp} para obter as instâncias mais centrais. Modificações no CNN são muito comuns \cite{cnn:1976}, porém, mesmo com estas modificações, o CNN ainda não é determinístico, pois a ordem em que as instâncias são classificadas afeta o resultado final.

%% TODO COLOCAR ALGUMA FIGURA PARA EXEMPLIFICAR
%% TODO EXPLICAR A FIGURA

Para o caso de estudo abordado neste trabalho, o CNN pode ser utilizado de forma adaptada. A adaptação consiste em manter todos os elementos da classe minoritária e o mínimo possível da classe marjoritária. O próprio CNN se encarrega de remover os elementos redundantes da classe marjoritária, assim, basta apenas selecionar todos os elementos da classe minoritária aos protótipos iniciais.
Segue abaixo o algoritmo desta adaptação:

\begin{algorithm}
\caption{CNN para bases desbalanceadas}
\label{alg:cnn_unbalanced}
\begin{algorithmic}[1]
	\REQUIRE {$list$: uma lista}
	\STATE Coloque todos os elementos da classe minoritária em $list$
	\FORALL {instância $e_i$ da base de dados original}
		\STATE Aplique o KNN sobre $e_i$ utilizando os elementos em $list$ para treinamento
		\IF {$e_i$ foi classificado erroneamente}
			\STATE salve $e_i$ em $list$
		\ENDIF
	\ENDFOR
	\RETURN base original - $list$
\end{algorithmic}
\end{algorithm}

Com o algoritmo CNN adaptado para bases desbalanceadas, os elementos redundantes da classe marjoritária são removidos, e todos os elementos da classe minoritária são mantidos. Esta adaptação do CNN irá reduzir a base de dados, ocasionando as vantagens de redução, e ainda reduzirá o desbalenceamento da base.


\section{Tomek Links}

Mantendo a mesma linha do ENN, Tomek Links é uma técnica de seleção de protótipos puramente seletiva que elimina os elementos das regiões de fronteiras e instâncias com probabilidade de ser ruído. Tomek Links podem ser definidos da seguinte forma: Dadas duas instâncias $e_i$ e $e_j$, o par \textit{($e_i$, $e_j$)} é chamado de Tomek Link se não existe nenhuma instância $e_k$, tal que, para todo $e_k$ \textit{dist($e_i$,$e_j$) < dist($e_i$,$e_k$)} e \textit{dist($e_i$,$e_j$) < dist($e_j$,$e_k$)}. Segue o algoritmo detalhado em \ref{alg:select_tomek_links}:

\begin{algorithm}
\caption{Seleciona Tomek Links}
\label{alg:select_tomek_links}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\FORALL {instância $e_i$ da base de dados original}
		\STATE $e_j$ = instância mais próxima de $e_i$
		\IF {instância mais p¿oxima de $e_j$ for $e_i$}
			\IF {classe de $e_i$ for diferente da classe de $e_j$}
				\STATE salve o par \textit{($e_i$, $e_j$)} em $list$
			\ENDIF
		\ENDIF
	\ENDFOR
	\RETURN $list$, Tomek Links
\end{algorithmic}
\end{algorithm}



Os Tomek Links representam elementos da região de fronteira e prováveis ruídos, e a técnica de seleção de protótipos consiste em remover os Tomek Links da base de dados original. O algoritmo da seleção de protótipos Tomek Links é apresentado em \ref{alg:tomek_links}:


\begin{algorithm}
\caption{Tomek Links}
\label{alg:tomek_links}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\STATE $list$ = $Seleciona Tomek Links$ da base original
	\FORALL {\textit{($e_i$, $e_j$)} em $list$}
		\STATE remova $e_i$ da base original
		\STATE remova $e_j$ da base original
	\ENDFOR
	\RETURN base original filtrada
\end{algorithmic}
\end{algorithm}


Enquanto o CNN remove os elementos que estão longe da região de indecisão, o Tomek Links remove os elementos que estão próximos desta região, o que causa uma maior separação entre as classes.


%% TODO FIGURA PARA TOMEK LINKS
%% EXPLICAR FIGURA


Observa-se facilmente que os Tomek Links pode remove todas as instâncias da fronteira, inclusive as instâncias da classe minoritária, assim sendo, uma possível adaptação dos Tomek Links é eliminar apenas os elementos das classes marjoritárias. Nesse caso, ainda ocorreria uma separação entre as classes, mas apenas as instâncias da classe marjoritária seriam removidos, dimunuindo assim o nível de desbalanceamento. Segue abaixo o algoritmo desta adaptação:


\begin{algorithm}
\caption{Tomek Links}
\label{alg:tomek_links_for_unbalanced_datasets}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\STATE $list$ = $Seleciona Tomek Links$ da base original
	\FORALL {\textit{($e_i$, $e_j$)} em $list$}
		\IF {$e_i$ for da classe marjoritária}
			\STATE remova $e_i$ da base original
		\ENDIF
		\IF {$e_j$ for da classe marjoritária}
			\STATE remova $e_j$ da base original
		\ENDIF
	\ENDFOR
	\RETURN base original - $list$
\end{algorithmic}
\end{algorithm}



Com esta adaptação, a classe minoritária é mantida, evitando o aumento do desbalanceamento ou a remoção por alta probabilidade de ruído.

\section{OSS}

One-Sided Selection \cite{conf/icml/KubatM97} é um método seletivo de seleção de protótipos, surgido pela combinação das técnicas CNN e Tomek Links. O algoritmo consiste na aplicação do CNN e depois da aplicação do Tomek Links como um filtro. O One-Sided Selection combina características das duas técnicas. A aplicação do CNN é feita para eliminar instâncias desnecessárias, redundantes, ou seja, instâncias que estão longe da fronteira de classificação. Já a aplicação do Tomek Links tem a função de remover elementos na fronteira de classificação, fazendo uma aparente separação das classes e removendo ruídos.

O OSS é muito utilizado para bases desbalanceadas, utilizando a adaptação do CNN, como monstrado no algoritmo \ref{alg:oss}.

\begin{algorithm}
\caption{One-Sided Selection}
\label{alg:oss}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
\REQUIRE {$tomek_links_list$: uma lista}
	\STATE $list$ = ${CNN para bases desbalanceadas}$ sobre a base original
	\STATE $list$ = ${Tomek Links para bases desbalanceadas}$ sobre $list$
	\RETURN $list$
\end{algorithmic}
\end{algorithm}


Observando o algoritmo, é fácil concluir que o One-Sided Selection é uma técnica apropriada para bases desbalanceadas. A aplicação do CNN adaptado elimina as instâncias redundantes da base marjoritária, colaborando para, além de diminuir a quantidade de instâncias longe da fronteira de classificação, diminuir o nível de desbalanceamento entre as classes. Já a aplicação do Tomek Links adaptado, elimina instâncias da classe marjoritária na fronteira de classificação, colaborando para maior delimitação da classe minoritária.

%%TODO colocar figura para exemplificar OSS
%%TODO explicar figura do OSS

Uma desvantagem do One-Sided Selection é que ele não é determinístico, o CNN é não-determinístico e como o One-Sided Selection faz a aplicação dele, torna o mesmo não-determinístico. O OSS poderia ser feito aplicando-se outro algoritmo no lugar do CNN, podendo assim, torna-lo determinístico. Este trabalho, porém, não abordará adaptações para o OSS, pois o mesmo já é apropriado para base de dados, e ser ou não determinístico, apesar de ser levado em consideração, não faz parte do escopo deste trabalho.


\section{LVQ}

Learning Vector Quantization proposto por Kohonen \cite{kohonen:lvq}. O Learning Vector quantization é um algoritmo supervisionado de síntese de protótipos, ou seja, cria novas instâncias baseadas em instâncias já existentes. A ideia básica do algoritmo é que dado um conjunto inicial de protótipos, o LVQ faz um ajuste dos protótipos, de forma a posicionar cada instância em um ponto que seja possível estabelecer uma função discriminante baseada nestes protótipos.

Uma desvantagem do LVQ é que a ordem das instâncias altera o resultado, ou seja, o algoritmo não é deterministico. Outra desvantagem é que, conforme será mostrado, o LVQ possui vários parâmetros, sendo necessário uma análise empírica dos valores apropriados para esses parâmetros.

Os protótipos iniciais podem ser escolhidos de qualquer forma, a idéia é que sejam protótipos que tenham boa representatividade da base de dados, mas também podem ser selecionados aleatoriamente, pois o próprio LVQ se encarrega de fazer os ajustes nestes protótipos.


\subsection{LVQ 1}

LVQ1 é a primeira versão do Learning Vector Quantization proposto por Kohonen. O algoritmo do LVQ1 basicamente seleciona alguns protótipos iniciais e ajusta esses protótipos utilizando a base original. Quando uma instância da base original é classificada erroneamente pelos protótipos, afasta-se o protótipo mais próximo, e quando é classificada corretamente, aproxima-se. O algoritmo detalhado pode ser visto em \ref{alg:lvq1}.


\begin{algorithm}
\caption{LVQ 1}
\label{alg:lvq1}
\begin{algorithmic}[1]
\REQUIRE {$prototypes$: uma lista para os protótipos}
\REQUIRE {$selection$: um algorítmo para seleção dos protótipos iniciais}
	\STATE $prototypes$ = $selection$ (base original)
	\WHILE{$prototypes$ não estiver sub-ajustado}
		\STATE $x$ = $ChooseOne$ (base original)
		\STATE $e_i$ = $SelectNearestFrom$($prototypes$, $x$)
		\IF {classe de $e_i$ $\neq$ classe de $x$}
			\STATE $e_i = e_i + \alpha(t) \times [x - e_i]$
		\ELSE
			\STATE $e_i = e_i - \alpha(t) \times [x - e_i]$
		\ENDIF
	\ENDWHILE
	\RETURN  $prototypes$
\end{algorithmic}
\end{algorithm}


A vantagem do LVQ1 é que ele estabiliza durante o treinamento, porém, ele possui um grande número de passos. Para a maioria dos problemas, o LVQ 1 possui um resultado satisfatório, mas além da demora, é necessário escolher os parâmetros corretamente.

Um dos parâmetros é o $\alpha(t)$, uma constante de ajuste, que serve para aproximar ou afastar os protótipos. Este afastamento ou aproximação é regulado pelo valor de $\alpha(t)$, sendo $0 < \alpha(t) < 1$. Percebe-se que $\alpha(t)$ foi colocado como uma função. Normalmente, essa função é uma exponencial descrescente, e o algoritmo termina quando $\alpha(t)$ se torna insignificante.

Outra questão do LVQ1 é escolher a quantidade de protótipos iniciais adequada, visto que, esta quantidade não é alterada durante toda a execução do algoritmo.

No caso de bases desbalanceadas, pode-se utilizar fatores de ajustes diferenciados para cada classe, ou escolher uma quantidade aproximada de cada classe para os protótipos iniciais. Fazendo estas adaptações, o LVQ1 poderá ter resultados melhores para bases desbalanceadas.

\subsection{Optimized-learning-rate LVQ}

Optimized-learning-rate LVQ [colocar referencia aqui http://www.springerlink.com/content/n72865x1t57q1877/] é uma versão otimizada do LVQ1, proposto para aumentar a velocidade de convergência do LVQ1. O modelo consiste basicamente em cada protótipo ter taxas de aprendizado individuais, a dinâmica da taxa de aprendizado consiste no aumento da mesma caso o protótipo esteja classificando corretamente e na diminuição, caso contrário.

\begin{center}
$\alpha(t) = \dfrac{\alpha(t-1)}{1 + s(t) \times \alpha(t-1)}$
\item
\item $s(t) = +1$, se $x$ é classificado corretamente
\item $s(t) = -1$, se $x$ é classificado erroneamente
\item $0 < \alpha(t) < 1$
\item
\end{center}

Com esta alteração do valor de $\alpha(t)$ faz com que o LVQ convirja mais rapidamente, tornando o algoritmo OLVQ mais viável em termos de performace e mantendo as características do LVQ1.

\subsection{LVQ 2.1}

Kohonen propos duas novas versões melhoradas do LVQ, uma delas é o LVQ 2.1. Esta nova versão do LVQ faz atualização nos dois protótipos mais próximos desde que as condições de ajuste sejam atendidas.

A ideia do LVQ 2.1 é ajustar apenas os protótipos próximos das fronteiras de classificação, região de indecisão. Para evitar uma divergência entre estes protótipos, foi introduzida a Regra da Janela.

Diz-se que um elemento está na janela quando ele obedece a regra da janela, isso acontece quando um elemento está na região de indecisão.

Dado um elemento $x$, diz-se que ele está na janela se:

\begin{center}

$\min{\frac{d_i}{d_j}}{\frac{d_j}{d_i}} > s$, onde $s = \dfrac{1 - w}{1 + w}$
\item $e_i$ e $e_j$ são os protótipos mais próximos de $x$
\item $d_i$ é a distância de $x$ para $e_i$
\item $d_j$ é a distância de $x$ para $e_j$
\item $w$ é a largura relativa
\end{center}

\begin{algorithm}
\caption{LVQ 2.1}
\label{alg:lvq21}
\begin{algorithmic}[1]
\REQUIRE {$prototypes$: uma lista para os protótipos}
	\STATE $prototypes$ = $LVQ 1$ (base original)
	\WHILE{$prototypes$ não estiver sub-ajustado}
		\STATE $x$ = $ChooseOne$ (base original)
		\STATE $e_i$, $e_j$ = $SelectNearestsFrom$($prototypes$, $x$)
		\IF {$CaiuNaJanela(x,e_i,e_j)$}
			\IF {$Classe(e_i) \ne Classe(e_j)$}
				\IF {$Classe(e_i) = Classe(x)$}
					\STATE $e_i = e_i + \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j - \alpha(t) \times [x - e_i]$
				\ELSE
					\STATE $e_i = e_i - \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j + \alpha(t) \times [x - e_i]$
				\ENDIF
			\ENDIF
		\ENDIF
	\ENDWHILE
	\RETURN  $prototypes$
\end{algorithmic}
\end{algorithm}

A algoritmo de LVQ 2.1 é aplicado depois do LVQ 1, mas ele ajusta dois protótipos a cada iteração. Esta técnica não faz ajustes de protótipos se $x$ não estiver na janela, se nenhum dos protótipos forem da classe de $x$ ou se os protótipos forem da mesma classe. Pode-se ver o algoritmo detalhado em \ref{alg:lvq21}.

Enquanto o LVQ1 provoca o afastamento dos protótipos nas regiões de indecisão, o LVQ 2.1 reduz esse afastamento atuando apenas sobre protótipos vizinhos pertencentes a classes diferentes.

Uma desvantagem do LVQ 2.1 é que além do custo ser maior, a aplicação do mesmo pode sobre-ajustar os protótipos nas regiões de indecisão. Para diminuir esse sobre-ajuste, foi criado o LVQ 3, abordado na próxima sessão.

\subsection{LVQ 3}

A segunda melhora proposta por Kohonen foi o LVQ 3. Este método tenta evitar o sobre-ajuste do LVQ 2.1 atuando também quando o elemento já está sendo classificado corretamente pelos dois protótipos mais próximos, aproximando ambos da instância utilizada para ajuste. Além disso, a terceira versão do LVQ introduz um fator de estabização $\epsilon$.

\begin{algorithm}
\caption{LVQ 3}
\label{alg:lvq3}
\begin{algorithmic}[1]
\REQUIRE {$prototypes$: uma lista para os protótipos}
	\STATE $prototypes$ = $LVQ 1$ (base original)
	\WHILE{$prototypes$ não estiver sub-ajustado}
		\STATE $x$ = $ChooseOne$ (base original)
		\STATE $e_i$, $e_j$ = $SelectNearestsFrom$($prototypes$, $x$)
		\IF {$CaiuNaJanela(x,e_i,e_j)$}
			\IF {$Classe(e_i) \ne Classe(e_j)$}
				\IF {$Classe(e_i) = Classe(x)$}
					\STATE $e_i = e_i + \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j - \alpha(t) \times [x - e_i]$
				\ELSE
					\STATE $e_i = e_i - \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j + \alpha(t) \times [x - e_i]$
				\ENDIF
			\ELSIF {$Classe(e_i) = Classe(e_j) = Classe(x)$}
				\STATE $e_i = e_i + \epsilon \times \alpha(t) \times [x - e_i]$
				\STATE $e_j = e_j + \epsilon \times \alpha(t) \times [x - e_i]$
			\ENDIF
		\ENDIF
	\ENDWHILE
	\RETURN  $prototypes$
\end{algorithmic}
\end{algorithm}


O fator de estabilização serve para suavizar o ajuste quando os protótipos já estão classificando corretamente $x$. O valor de $\epsilon$ deve ser tal que $0 < \epsilon < 1$.

Assim como as outras versões do LVQ, o LVQ 3 é robusto, mas seu maior problema é determinar o valor de tantos parâmetros como $\alpha, \epsilon$ e $w$. Porém, a maior desvantagem é não ser possível saber com certeza quando os protótipos foram ou não sobre-ajustados.

\section{SGP}

Self-Generating Prototypes \cite{fayed:sgp} é uma técnica de síntese de protótipos muito completa. Sua maior vantagem é que, enquanto muitas técnicas de seleção de protótipos dependem da escolha correta do número de protótipos iniciais ou possuem muitos parâmetros, o SGP encontra a quantidade de protótipos e a localização de cada uma em sua fase de treinamento, sem supervisão humana.

A ideia principal do SGP é formar um certo número de grupos e eleger representantes para esses grupos. Conforme necessário, o algorítmo divide os grupos ou move instâncias de um grupo para outro.

Inicialmente, para cada classe, é criado um grupo contendo todas as instâncias daquela classe. Com os grupos feitos, são obtidos os centróides de cada grupo e estes são chamados representantes do grupo. Depois, para cada grupo, faça os passos abaixo até que não haja mais alterações em nenhum grupo.

\begin{figure}
\label{fig:divisaogrupossgp}
\includegraphics[scale=0.55]{imagens/SGP1.eps}
\caption{Etapa da divisão de grupos. Figura obtida de \cite{csp:sgp}} 
\end{figure}

\begin{itemize}
\item Se para todos os padrões de um grupo o protótipo mais próximo é o centróide do grupo, então nenhuma operação é realizada.
\item Se para todos os padrões de um grupo o protótipo mais próximo é de uma classe diferente da do grupo, ele é dividido em dois subgrupos \ref{fig:divisaogrupossgp}. Essa divisão é feita separando os padrões pelo hiperplano que passa pelo centroide do grupo, e cujo vetor normal é a primeira componente principal gerada pelos padrões do grupo.
\item Se para alguns padrões de um grupo o protótipo mais próximo é diferente do centróide, mas da mesma classe, esses padrões são deslocados do grupo original para o grupo do protótipo mais próximo
\item Se para alguns padrões de um grupo o protótipo mais próximo não é o centróide e é de uma classe diferente, estes padrões são removidos do grupo original e formam um novo grupo, sendo o centróide computado como um novo protótipo.
\end{itemize}

No final de cada iteração, o centróide de cada grupo é computado novamente. O processo se repete até que não haja alterações em mais nenhum grupo. Uma descrição mais formal do algoritmo é descrita em \ref{alg:sgp1}

\begin{algorithm}
\caption{SGPS 1}
\label{alg:sgp1}
\begin{algorithmic}[1]
\REQUIRE {$PS$: uma lista para os representantes}
\REQUIRE {$GS$: uma lista de grupos de instâncias}
\REQUIRE {$T$: uma lista de duplas de instâncias}
	\FORALL {classe $C$}
		\STATE $G$ = $\bigcup$ instâncias da classe $C$
		\STATE $Adicione(G, GS)$
		\STATE $Adicione(Centroide(G),PS)$ 
	\ENDFOR
	\STATE $count = 1$
	\WHILE {$count \ne 0$}
		\STATE $count$ = $Quantidade(GS)$
		\STATE $Limpe(T)$
		\FORALL {$G$ em $GS$} 
			\STATE $P$ = Representante de $G$
			\FORALL {$e_i$ em $group$}
				\STATE $NearestP$ = $1NN(e_i, PS)$
				\STATE $Adicione((e_i,NearestP), T)$
			\ENDFOR
			\IF {$\forall$ $e_i, NearestP$ em $T$, $NearestPS$ = $P$}
				\STATE $count$ = $count - 1$
			\ELSIF {$\forall$ $e_i, NearestP$ em $T$, a $Classe(NearestP) \ne Classe(P)$} 
				\STATE $Vector = PrimeiraComponentePrincipal(G)$
				\STATE $Hiperplano$ = hiperplano que passa pelo centróide de $G$ e cujo vetor normal é a $Vector$.
				\STATE Divida $G$ em 2 grupos, instâncias acima e abaixo de $Hiperplano$
				\STATE Atualize $GS$ e $PS$.
			\ELSIF {$\exists$ $e_i, NearestP$ em $T$ tal que $NearestP \ne P$ e $Classe(NearestP) = Classe(P)$}
				\STATE Remova $e_i$ de $G$ e adicione a grupo de $NearestP$.
				\STATE Atualize $GPS$ e $PS$.
			\ELSIF {$\exists$ $e_i, NearestP$ em $T$ tal que o $Classe(NearestP) != Classe(P)$}
				\STATE Remova $e_i$ de $G$.
				\STATE Crie um novo grupo contendo as instâncias removidas.
				\STATE Atualize $PS$ e $GS$,
			\ENDIF
		\ENDFOR
	\ENDWHILE
	\RETURN  $PS$
\end{algorithmic}
\end{algorithm}

Observando o algoritmo do SGP1 \ref{alg:sgp1}, percebe-se que apesar do conceito ser bem simples, esta técnica possui alguns passos complexos, sendo necessário conhecimentos sobre extração de características [REFERÊNCIA PCA AQUI]. Principal Component Analysis é a técnica utilizada para traçar o vetor perpendicular ao hiperplano \ref{fig:divisaogrupossgp}.

A maior vantagem do SGP1 é que, conforme citado anteriormente, ele é não depende de parâmetros como quantidade de protótipos iniciais nem valores específicos. Por ser um algoritmo deterministico, o SGP1 executado numa mesma base de dados, sempre gerará os mesmos protótipos. Estes protótipos gerados possuem excelente representatividade do conjunto de treinamento, tanto que, utilizando-se os protótipos gerados como treinamento de um KNN, e classificando-se todas as instâncias de treinamento do SGP1, a taxa de acerto é de 100\%. Claro que o treinamento não pode ser utilizado para teste, mas isto mostra a boa representatividade das instâncias geradas pelo SGP1.

Porém, o SGP1 também apresenta desvantagens. Uma delas é que o SGP1 é muito custoso, exigindo, em geral, um treinamento mais longo que outras técnicas.

Outra desvantagem é que o SGP1 é sensível a ruídos, pois, se necessário, o algoritmo criará um grupo com apenas uma instância. No caso de um ruído, isto será muito desvantajoso, considerando que, em experimentos diversos, o SGP1 conseguiu reduzir em mais de 100 vezes o tamanho da base de dados.

Apesar das desvantagens citadas, bases desbalanceadas podem ser beneficiadas com o SGP1, considerando que ele considera os agrupamentos de classes, e não a quantidade de instâncias em cada classe.

\section{SGP 2}

Para reduzir ainda mais a quantidade de protótipos gerados pelo SGP1, foi criado uma nova versão, o SGP2. Basicamente, o SGP2 adiciona apenas 2 etapas ao SGP1. Estas etapas são prunning e merge.



\section{CCNN}


