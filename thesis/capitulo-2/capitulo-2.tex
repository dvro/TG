% !TEX encoding = ISO-8859-1
\chapter{Técnicas de Seleção de Protótipos}
% \label{ch:tecnicasdeselecaodeprototipos}

Neste capítulo, serão explicadas as técnicas de seleção de protótipos analisadas neste trabalho. Cada uma das sessões abaixo aborda conceitos básicos, pseudo-código e características de cada técnica, assim como possíveis adaptações nos seus algoritmos para tratar bases desbalanceadas.

\section{ENN}

Edited Nearest Neighbor Rule\cite{enn:2011} é uma técnica de seleção de protótipos puramente seletiva proposta por Wilson em 1976. De uma forma geral, esta técnica foi projetada para funcionar como um filtro de ruídos, eliminando instâncias na região de fronteira, região de alta susceptibilidade a erros.

Por atuar apenas na região de fronteira, esta técnica possui uma baixa capacidade de redução. Seu algoritmo mantém as instâncias que não estão localizadas nesta região, exceto no caso de instâncias com extrema probabilidade de erro.

O algoritmo do ENN está demonstrado em Algorithm \ref{alg:enn}.

\begin{algorithm}[H][h]
\caption{ENN}
\label{alg:enn}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
\FORALL {instância $e_i$ da base de dados original}
\STATE Aplique o KNN sobre $e_i$
\IF {$e_i$ foi classificado erroneamente}
\STATE salve $e_i$ em $list$
\ENDIF
\ENDFOR
\STATE Remova da base de dados todos os elementos que estão em $list$
\end{algorithmic}
\end{algorithm}

O valor de K usado pelo KNN pode variar de acordo com o tamanho da base de dados, porém, tipicamente, utiliza-se K=3. Em geral, O valor de K é inversamente proporcional a quantidade de instâncias que serão eliminadas, ou seja, para que o filtro elimine todos os possíveis ruídos, deve-se utilizar K=1, mas com isso, elimina-se também instâncias não ruidosas.

\begin{figure}[H]
\label{fig:enn}
\includegraphics[scale=0.40]{imagens/enn.eps}
\caption{ENN aplicado com K=3}
\end{figure}

Na Figura \ref{fig:enn} pode-se observar uma base de dados com duas classes. No primeiro gráfico da figura, observar-se a base de dados original, antes da aplicação do ENN. No segundo gráfico, foi aplicado o ENN, Algorithm \ref{alg:enn}, com K=3 sobre a base de dados. Os pontos pretos representam pontos que foram classificados erroneamente com a aplicação do KNN, a região circulada engloba os K elementos mais próximos do ruído. Mesmo um elemento que será posteriormente eliminado pode ser utilizado para eliminar ou manter outra instância, visto que as remoções são feitas apenas no fim da execução.

O mais interessante do caso acima é que, após a aplicação do ENN, as classes ficaram bem separadas pelos quadrantes pontilhados, mostrando a eficiência do ENN para a base de dados acima.

Uma vantagem do ENN é que ele independe da ordem que a base de dados foi apresentada, ou seja, o ENN aplicado a uma base de dados, com o mesmo valor de K, sempre terá o mesmo resultado.

Porém, o ENN também apresenta desvantagens, ele possui uma baixa capacidade de redução, pois elimina apenas ruídos, mantendo instâncias que são desnecessárias, que apresentam apenas redundância de informação. No caso da Figura \ref{fig:enn}, a base poderia ser representada por 4 instâncias bem posicionadas ou, por se tratar de uma técnica seletiva, com 8 instâncias, porém, o ENN manteve 13 instâncias, eliminando apenas 3.

Pelas suas características, normalmente o ENN é utilizado como método de pré-processamento da base de dados, eliminando apenas instâncias que apresentam alta probabilidade de serem ruídos.

No caso de bases desbalanceadas, o ENN pode tratar todas as instâncias da base minoritária como ruídos, caso a base seja altamente desbalanceada (isto será demonstrado posteriormente com exemplos), aumentando ainda mais o nível de desbalanceamento. Uma possível adaptação para o ENN em bases altamente desbalanceadas é eliminar apenas os elementos que sejam da classe marjoritária. O algoritmo adaptado está demonstrado em Algorithm \ref{alg:enn_for_unbalanced_datasets}.

\begin{algorithm}[H][h][h]
\caption{ENN}
\label{alg:enn_for_unbalanced_datasets}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\FORALL {instância $e_i$ da base de dados original}
		\STATE Aplique o KNN sobre $e_i$
		\IF {$e_i$ foi classificado erroneamente}
			\IF {$e_i$ for da classe marjoritária}
				\STATE salve $e_i$ em $list$
			\ENDIF
		\ENDIF
	\ENDFOR
	\STATE Remova da base de dados todos os elementos que estão em $list$
\end{algorithmic}
\end{algorithm}

Com este algoritmo adaptado, as instâncias da classe minoritária seriam mantidas, e a região delimitada por ela ficaria mais bem definida.

\section{CNN}

Condensed Nearest Neighbor \cite{cnn:1968} é uma técnica de seleção de protótipos puramente seletiva que tem como objetivo eliminar informação redundante. Diferentemente do ENN \cite{enn:2011}, o CNN não elimina instâncias nas regiões de fronteira, a técnica mantém estes elementos pois considera que estes "são os importantes" para distinguir entre duas classes.

A ideia geral do CNN é encontrar o menor subconjunto da base de dados original que, utilizando o 1-NN, classifica todos os padrões da base corretamente. Fazendo isso, o algoritmo elimina os elementos mais afastados da região de indecisão, da fronteira de classificação.

O algoritmo do CNN está descrito em Algorithm \ref{alg:cnn}.

\begin{algorithm}[H][h]
\caption{CNN}
\label{alg:cnn}
\begin{algorithmic}[1]
	\REQUIRE {$list$: uma lista}
	\STATE Escolha um elemento de cada classe $aleatoreamente$ e coloque-os em $list$
	\FORALL {instância $e_i$ da base de dados original}
		\STATE $KNN(e_i,list)$
		\IF {$e_i$ foi classificado erroneamente}
			\STATE salve $e_i$ em $list$
		\ENDIF
	\ENDFOR
	\RETURN $list$, os protótipos
\end{algorithmic}
\end{algorithm}

Pode-se observar que este algoritmo possui uma abordagem totalmente diferente do ENN, pois ele começa com um conjunto mínimo de instâncias (uma de cada classe) e depois adiciona instâncias conforme a necessidade de mantê-las para que todos os elementos da base de dados original sejam classificados corretamente.

Um ponto importante na descrição do algoritmo, é a palavra $aleatoriamente$, o que significa que o CNN aplicado numa mesma base de dados com um mesmo valor de K para o KNN, nem sempre resulta nos mesmos protótipos. O primeiro fato para que isso ocorra é a seleção aleatória dos protótipos iniciais, a segunda é a ordem em que as instâncias são visitadas pelo algoritmo. 

Existem algumas adaptações para o CNN, onde os protótipos iniciais são escolhidos utilizando técnicas como o SGP\cite{fayed:sgp} para obter as instâncias mais centrais. Modificações no CNN são muito comuns \cite{cnn:1976}, porém, mesmo com estas modificações, o CNN ainda não é determinístico, pois a ordem em que as instâncias são classificadas afeta o resultado final.

\begin{figure}[H]
\label{fig:cnn}
\includegraphics[scale=0.40]{imagens/cnn.eps}
\caption{Exemplo da aplicação do CNN}
\end{figure}

No primeiro gráfico da figura \ref{fig:cnn} é mostrado uma base de dados qualquer, no segundo gráfico, é mostrado o resultado do CNN aplicado nesta base. Observa-se que uma grande quantidade de instâncias foi eliminada, mas praticamente todas as instâncias próximas da região de fronteira foram mantidas. Ainda existem instâncias redundantes nesta base, mas como citado anteriormente, isto acontece por conta da escolha aleatória dos protótipos iniciais e da ordem em que as instâncias são visitadas pelo algoritmo.

Para o caso de estudo abordado neste trabalho, o CNN pode ser utilizado de forma adaptada. A adaptação consiste em manter todos os elementos da classe minoritária e o mínimo possível da classe marjoritária. O próprio CNN se encarrega de remover os elementos redundantes da classe marjoritária, assim, basta apenas selecionar todos os elementos da classe minoritária aos protótipos iniciais.
Segue em Algorithm \ref{alg:cnn_unbalanced}, o algoritmo desta adaptação:

\begin{algorithm}[H][h]
\caption{CNN para bases desbalanceadas}
\label{alg:cnn_unbalanced}
\begin{algorithmic}[1]
	\REQUIRE {$list$: uma lista}
	\STATE Coloque todos os elementos da classe minoritária em $list$
	\FORALL {instância $e_i$ da base de dados original}
		\STATE Aplique o KNN sobre $e_i$ utilizando os elementos em $list$ para treinamento
		\IF {$e_i$ foi classificado erroneamente}
			\STATE salve $e_i$ em $list$
		\ENDIF
	\ENDFOR
	\RETURN base original - $list$
\end{algorithmic}
\end{algorithm}

Com o algoritmo CNN adaptado para bases desbalanceadas, os elementos redundantes da classe marjoritária são removidos, e todos os elementos da classe minoritária são mantidos. Com esta adaptação, além da redução do número de instâncias, também é reduzido o nível de desbalanceamento da base de dados.


\section{Tomek Links}

Mantendo a mesma linha do ENN, Tomek Links é uma técnica de seleção de protótipos puramente seletiva que elimina os elementos das regiões de fronteiras e instâncias com probabilidade de serem ruído. Tomek Links podem ser definidos da seguinte forma: Dadas duas instâncias $e_i$ e $e_j$, o par \textit{($e_i$, $e_j$)} é chamado de Tomek Link se não existe nenhuma instância $e_k$, tal que, para todo $e_k$ \textit{dist($e_i$,$e_j$) < dist($e_i$,$e_k$)} e \textit{dist($e_i$,$e_j$) < dist($e_j$,$e_k$)}. Segue o algoritmo detalhado em Algorithm \ref{alg:select_tomek_links}:

\begin{algorithm}[H][h]
\caption{Seleciona Tomek Links}
\label{alg:select_tomek_links}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\FORALL {instância $e_i$ da base de dados original}
		\STATE $e_j$ = instância mais próxima de $e_i$
		\IF {instância mais p¿oxima de $e_j$ for $e_i$}
			\IF {classe de $e_i$ for diferente da classe de $e_j$}
				\STATE salve o par \textit{($e_i$, $e_j$)} em $list$
			\ENDIF
		\ENDIF
	\ENDFOR
	\RETURN $list$, Tomek Links
\end{algorithmic}
\end{algorithm}

Os Tomek Links representam elementos da região de indecisão e prováveis ruídos, e a técnica de seleção de protótipos consiste em remover os Tomek Links da base de dados original. O algoritmo Tomek Links é apresentado em \ref{alg:tomek_links}:

\begin{algorithm}[H][h]
\caption{Tomek Links}
\label{alg:tomek_links}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\STATE $list$ = $Seleciona Tomek Links$ da base original
	\FORALL {\textit{($e_i$, $e_j$)} em $list$}
		\STATE remova $e_i$ da base original
		\STATE remova $e_j$ da base original
	\ENDFOR
	\RETURN base original filtrada
\end{algorithmic}
\end{algorithm}


Enquanto o CNN remove os elementos que estão longe da região de indecisão, o Tomek Links remove os elementos que estão próximos desta região, o que causa uma maior separação entre as classes.

\begin{figure}[H]
\label{fig:tomek_links}
\includegraphics[scale=0.40]{imagens/tomek_links.eps}
\caption{Exemplo da aplicação do Tomek Links}
\end{figure}

Na Figura \ref{fig:tomek_links} está exemplificada a aplicação do Tomek Links. No primeiro gráfico está a base original, e estão circulados os Tomek Links que, no segundo gráfico, foram removidos. No segundo gráfico, a base de dados foi filtrada e a maioria dos ruídos removidos. No exemplo desta figura, o Tomek Links fez uma separação entre as classes, eliminando parte de intersecção entre as mesmas.

Uma desvantagem do Tomek Links é que esta técnica elimina as duas instâncias presentes no Tomek Link, com isso, instâncias não ruidosas podem estar sendo removidas, instâncias estas que podem representar informação importante para a base de dados.

Observa-se facilmente que o Tomek Links pode remover todas as instâncias de regiões de indecisão, inclusive as instâncias da classe minoritária. Sendo assim, uma adaptação dos Tomek Links é eliminar apenas os elementos das classes marjoritárias. Nesse caso, ainda ocorre uma separação entre as classes, mas as instâncias dos Tomek Links que forem das classes minoritárias são mantidas, diminuindo o nível de desbalanceamento. O algoritmo desta adaptação está demonstrado em Algorithm \ref{alg:tomek_links_for_unbalanced_datasets}.

\begin{algorithm}[H][h]
\caption{Tomek Links}
\label{alg:tomek_links_for_unbalanced_datasets}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
	\STATE $list$ = $Seleciona Tomek Links$ da base original
	\FORALL {\textit{($e_i$, $e_j$)} em $list$}
		\IF {$e_i$ for da classe marjoritária}
			\STATE remova $e_i$ da base original
		\ENDIF
		\IF {$e_j$ for da classe marjoritária}
			\STATE remova $e_j$ da base original
		\ENDIF
	\ENDFOR
	\RETURN base original - $list$
\end{algorithmic}
\end{algorithm}

Com esta adaptação, a classe minoritária é mantida, evitando o aumento do desbalanceamento ou a remoção por alta probabilidade de ruído.


\section{OSS}

One-Sided Selection \cite{conf/icml/KubatM97} é um método seletivo de seleção de protótipos, surgido pela combinação das técnicas CNN e Tomek Links. O algoritmo consiste na aplicação do CNN e depois da aplicação do Tomek Links como um filtro. O One-Sided Selection combina características das duas técnicas. A aplicação do CNN é feita para eliminar instâncias desnecessárias, redundantes, ou seja, instâncias que estão longe da fronteira de classificação. Já a aplicação do Tomek Links tem a função de remover elementos na fronteira de classificação, fazendo uma aparente separação das classes e removendo ruídos.

O OSS é muito utilizado para bases desbalanceadas, utilizando a adaptação do CNN, como monstrado no algoritmo \ref{alg:oss}.

\begin{algorithm}[H][h]
\caption{One-Sided Selection}
\label{alg:oss}
\begin{algorithmic}[1]
\REQUIRE {$list$: uma lista}
\REQUIRE {$tomek_links_list$: uma lista}
	\STATE $list$ = ${CNN para bases desbalanceadas}$ sobre a base original
	\STATE $list$ = ${Tomek Links para bases desbalanceadas}$ sobre $list$
	\RETURN $list$
\end{algorithmic}
\end{algorithm}


Observando o algoritmo, é fácil concluir que o One-Sided Selection é uma técnica apropriada para bases desbalanceadas. A aplicação do CNN adaptado elimina as instâncias redundantes da base marjoritária, colaborando para, além de diminuir a quantidade de instâncias longe da fronteira de classificação, diminuir o nível de desbalanceamento entre as classes. Já a aplicação do Tomek Links adaptado, elimina instâncias da classe marjoritária na fronteira de classificação, colaborando para maior delimitação da classe minoritária.

\begin{figure}[H]
\label{fig:oss1}
\includegraphics[scale=0.40]{imagens/oss_1.eps}
\caption{Base Original antes da aplicação do OSS}
\end{figure}

\begin{figure}[H]
\label{fig:oss2}
\includegraphics[scale=0.40]{imagens/oss_2.eps}
\caption{Aplicação da primeira etapa do OSS, o CNN}
\end{figure}

\begin{figure}[H]
\label{fig:oss3}
\includegraphics[scale=0.40]{imagens/oss_3.eps}
\caption{Resultado final do OSS, após aplicação da segunda etapa, o Tomek Links}
\end{figure}

Nas Figuras \ref{fig:oss1}, \ref{fig:oss2} e \ref{fig:oss3} . 




Uma desvantagem do One-Sided Selection é que ele não é determinístico, o CNN é não-determinístico e como o One-Sided Selection faz a aplicação dele, torna o mesmo não-determinístico. O OSS poderia ser feito aplicando-se outro algoritmo no lugar do CNN, podendo assim, torna-lo determinístico. Este trabalho, porém, não abordará adaptações para o OSS, pois o mesmo já é apropriado para base de dados, e ser ou não determinístico, apesar de ser levado em consideração, não faz parte do escopo deste trabalho.


\section{LVQ}

Learning Vector Quantization proposto por Kohonen \cite{kohonen:lvq}. O Learning Vector quantization é um algoritmo supervisionado de síntese de protótipos, ou seja, cria novas instâncias baseadas em instâncias já existentes. A ideia básica do algoritmo é que dado um conjunto inicial de protótipos, o LVQ faz um ajuste dos protótipos, de forma a posicionar cada instância em um ponto que seja possível estabelecer uma função discriminante baseada nestes protótipos.

Uma desvantagem do LVQ é que a ordem das instâncias altera o resultado, ou seja, o algoritmo não é deterministico. Outra desvantagem é que, conforme será mostrado, o LVQ possui vários parâmetros, sendo necessário uma análise empírica dos valores apropriados para esses parâmetros.

Os protótipos iniciais podem ser escolhidos de qualquer forma, a idéia é que sejam protótipos que tenham boa representatividade da base de dados, mas também podem ser selecionados aleatoriamente, pois o próprio LVQ se encarrega de fazer os ajustes nestes protótipos.


\subsection{LVQ 1}

LVQ1 é a primeira versão do Learning Vector Quantization proposto por Kohonen. O algoritmo do LVQ1 basicamente seleciona alguns protótipos iniciais e ajusta esses protótipos utilizando a base original. Quando uma instância da base original é classificada erroneamente pelos protótipos, afasta-se o protótipo mais próximo, e quando é classificada corretamente, aproxima-se. O algoritmo detalhado pode ser visto em \ref{alg:lvq1}.


\begin{algorithm}[H][h]
\caption{LVQ 1}
\label{alg:lvq1}
\begin{algorithmic}[1]
\REQUIRE {$prototypes$: uma lista para os protótipos}
\REQUIRE {$selection$: um algorítmo para seleção dos protótipos iniciais}
	\STATE $prototypes$ = $selection$ (base original)
	\WHILE{$prototypes$ não estiver sub-ajustado}
		\STATE $x$ = $ChooseOne$ (base original)
		\STATE $e_i$ = $SelectNearestFrom$($prototypes$, $x$)
		\IF {classe de $e_i$ $\neq$ classe de $x$}
			\STATE $e_i = e_i + \alpha(t) \times [x - e_i]$
		\ELSE
			\STATE $e_i = e_i - \alpha(t) \times [x - e_i]$
		\ENDIF
	\ENDWHILE
	\RETURN  $prototypes$
\end{algorithmic}
\end{algorithm}


A vantagem do LVQ1 é que ele estabiliza durante o treinamento, porém, ele possui um grande número de passos. Para a maioria dos problemas, o LVQ 1 possui um resultado satisfatório, mas além da demora, é necessário escolher os parâmetros corretamente.

Um dos parâmetros é o $\alpha(t)$, uma constante de ajuste, que serve para aproximar ou afastar os protótipos. Este afastamento ou aproximação é regulado pelo valor de $\alpha(t)$, sendo $0 < \alpha(t) < 1$. Percebe-se que $\alpha(t)$ foi colocado como uma função. Normalmente, essa função é uma exponencial descrescente, e o algoritmo termina quando $\alpha(t)$ se torna insignificante.

Outra questão do LVQ1 é escolher a quantidade de protótipos iniciais adequada, visto que, esta quantidade não é alterada durante toda a execução do algoritmo.

No caso de bases desbalanceadas, pode-se utilizar fatores de ajustes diferenciados para cada classe, ou escolher uma quantidade aproximada de cada classe para os protótipos iniciais. Fazendo estas adaptações, o LVQ1 poderá ter resultados melhores para bases desbalanceadas.

\subsection{Optimized-learning-rate LVQ}

Optimized-learning-rate LVQ [colocar referencia aqui http://www.springerlink.com/content/n72865x1t57q1877/] é uma versão otimizada do LVQ1, proposto para aumentar a velocidade de convergência do LVQ1. O modelo consiste basicamente em cada protótipo ter taxas de aprendizado individuais, a dinâmica da taxa de aprendizado consiste no aumento da mesma caso o protótipo esteja classificando corretamente e na diminuição, caso contrário.

\begin{center}
$\alpha(t) = \dfrac{\alpha(t-1)}{1 + s(t) \times \alpha(t-1)}$
\item
\item $s(t) = +1$, se $x$ é classificado corretamente
\item $s(t) = -1$, se $x$ é classificado erroneamente
\item $0 < \alpha(t) < 1$
\item
\end{center}

Com esta alteração do valor de $\alpha(t)$ faz com que o LVQ convirja mais rapidamente, tornando o algoritmo OLVQ mais viável em termos de performace e mantendo as características do LVQ1.

\subsection{LVQ 2.1}

Kohonen propos duas novas versões melhoradas do LVQ, uma delas é o LVQ 2.1. Esta nova versão do LVQ faz atualização nos dois protótipos mais próximos desde que as condições de ajuste sejam atendidas.

A ideia do LVQ 2.1 é ajustar apenas os protótipos próximos das fronteiras de classificação, região de indecisão. Para evitar uma divergência entre estes protótipos, foi introduzida a Regra da Janela.

Diz-se que um elemento está na janela quando ele obedece a regra da janela, isso acontece quando um elemento está na região de indecisão.

Dado um elemento $x$, diz-se que ele está na janela se:

\begin{center}

$\min{\frac{d_i}{d_j}}{\frac{d_j}{d_i}} > s$, onde $s = \dfrac{1 - w}{1 + w}$
\item $e_i$ e $e_j$ são os protótipos mais próximos de $x$
\item $d_i$ é a distância de $x$ para $e_i$
\item $d_j$ é a distância de $x$ para $e_j$
\item $w$ é a largura relativa
\end{center}

\begin{algorithm}[H][h]
\caption{LVQ 2.1}
\label{alg:lvq21}
\begin{algorithmic}[1]
\REQUIRE {$prototypes$: uma lista para os protótipos}
	\STATE $prototypes$ = $LVQ 1$ (base original)
	\WHILE{$prototypes$ não estiver sub-ajustado}
		\STATE $x$ = $ChooseOne$ (base original)
		\STATE $e_i$, $e_j$ = $SelectNearestsFrom$($prototypes$, $x$)
		\IF {$CaiuNaJanela(x,e_i,e_j)$}
			\IF {$Classe(e_i) \ne Classe(e_j)$}
				\IF {$Classe(e_i) = Classe(x)$}
					\STATE $e_i = e_i + \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j - \alpha(t) \times [x - e_i]$
				\ELSE
					\STATE $e_i = e_i - \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j + \alpha(t) \times [x - e_i]$
				\ENDIF
			\ENDIF
		\ENDIF
	\ENDWHILE
	\RETURN  $prototypes$
\end{algorithmic}
\end{algorithm}

A algoritmo de LVQ 2.1 é aplicado depois do LVQ 1, mas ele ajusta dois protótipos a cada iteração. Esta técnica não faz ajustes de protótipos se $x$ não estiver na janela, se nenhum dos protótipos forem da classe de $x$ ou se os protótipos forem da mesma classe. Pode-se ver o algoritmo detalhado em \ref{alg:lvq21}.

Enquanto o LVQ1 provoca o afastamento dos protótipos nas regiões de indecisão, o LVQ 2.1 reduz esse afastamento atuando apenas sobre protótipos vizinhos pertencentes a classes diferentes.

Uma desvantagem do LVQ 2.1 é que além do custo ser maior, a aplicação do mesmo pode sobre-ajustar os protótipos nas regiões de indecisão. Para diminuir esse sobre-ajuste, foi criado o LVQ 3, abordado na próxima sessão.

\subsection{LVQ 3}

A segunda melhora proposta por Kohonen foi o LVQ 3. Este método tenta evitar o sobre-ajuste do LVQ 2.1 atuando também quando o elemento já está sendo classificado corretamente pelos dois protótipos mais próximos, aproximando ambos da instância utilizada para ajuste. Além disso, a terceira versão do LVQ introduz um fator de estabização $\epsilon$.

\begin{algorithm}[H][h]
\caption{LVQ 3}
\label{alg:lvq3}
\begin{algorithmic}[1]
\REQUIRE {$prototypes$: uma lista para os protótipos}
	\STATE $prototypes$ = $LVQ 1$ (base original)
	\WHILE{$prototypes$ não estiver sub-ajustado}
		\STATE $x$ = $ChooseOne$ (base original)
		\STATE $e_i$, $e_j$ = $SelectNearestsFrom$($prototypes$, $x$)
		\IF {$CaiuNaJanela(x,e_i,e_j)$}
			\IF {$Classe(e_i) \ne Classe(e_j)$}
				\IF {$Classe(e_i) = Classe(x)$}
					\STATE $e_i = e_i + \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j - \alpha(t) \times [x - e_i]$
				\ELSE
					\STATE $e_i = e_i - \alpha(t) \times [x - e_i]$
					\STATE $e_j = e_j + \alpha(t) \times [x - e_i]$
				\ENDIF
			\ELSIF {$Classe(e_i) = Classe(e_j) = Classe(x)$}
				\STATE $e_i = e_i + \epsilon \times \alpha(t) \times [x - e_i]$
				\STATE $e_j = e_j + \epsilon \times \alpha(t) \times [x - e_i]$
			\ENDIF
		\ENDIF
	\ENDWHILE
	\RETURN  $prototypes$
\end{algorithmic}
\end{algorithm}


O fator de estabilização serve para suavizar o ajuste quando os protótipos já estão classificando corretamente $x$. O valor de $\epsilon$ deve ser tal que $0 < \epsilon < 1$.

Assim como as outras versões do LVQ, o LVQ 3 é robusto, mas seu maior problema é determinar o valor de tantos parâmetros como $\alpha, \epsilon$ e $w$. Porém, a maior desvantagem é não ser possível saber com certeza quando os protótipos foram ou não sobre-ajustados.

\section{SGP}

Self-Generating Prototypes \cite{fayed:sgp} é uma técnica de síntese de protótipos muito completa. Sua maior vantagem é que, enquanto muitas técnicas de seleção de protótipos dependem da escolha correta do número de protótipos iniciais ou possuem muitos parâmetros, o SGP encontra a quantidade de protótipos e a localização de cada uma em sua fase de treinamento, sem supervisão humana.

A ideia principal do SGP é formar um certo número de grupos e eleger representantes para esses grupos. Conforme necessário, o algorítmo divide os grupos ou move instâncias de um grupo para outro.

Inicialmente, para cada classe, é criado um grupo contendo todas as instâncias daquela classe. Com os grupos feitos, são obtidos os centróides de cada grupo e estes são chamados representantes do grupo. Depois, para cada grupo, faça os passos abaixo até que não haja mais alterações em nenhum grupo.

\begin{figure}[H]
\label{fig:divisaogrupossgp}
\includegraphics[scale=0.55]{imagens/SGP1.eps}
\caption{Etapa da divisão de grupos. Figura obtida de \cite{csp:sgp}} 
\end{figure}

\begin{itemize}
\item Se para todos os padrões de um grupo o protótipo mais próximo é o centróide do grupo, então nenhuma operação é realizada.
\item Se para todos os padrões de um grupo o protótipo mais próximo é de uma classe diferente da do grupo, ele é dividido em dois subgrupos \ref{fig:divisaogrupossgp}. Essa divisão é feita separando os padrões pelo hiperplano que passa pelo centroide do grupo, e cujo vetor normal é a primeira componente principal gerada pelos padrões do grupo.
\item Se para alguns padrões de um grupo o protótipo mais próximo é diferente do centróide, mas da mesma classe, esses padrões são deslocados do grupo original para o grupo do protótipo mais próximo
\item Se para alguns padrões de um grupo o protótipo mais próximo não é o centróide e é de uma classe diferente, estes padrões são removidos do grupo original e formam um novo grupo, sendo o centróide computado como um novo protótipo.
\end{itemize}

No final de cada iteração, o centróide de cada grupo é computado novamente. O processo se repete até que não haja alterações em mais nenhum grupo. Uma descrição mais formal do algoritmo é descrita em \ref{alg:sgp1}

\begin{algorithm}[H][h]
\caption{SGP 1}
\label{alg:sgp1}
\begin{algorithmic}[1]
\REQUIRE {$PS$: uma lista para os representantes}
\REQUIRE {$GS$: uma lista de grupos de instâncias}
\REQUIRE {$T$: uma lista de duplas de instâncias}
	\FORALL {classe $C$}
		\STATE $G$ = $\bigcup$ instâncias da classe $C$
		\STATE $Adicione(G, GS)$
		\STATE $Adicione(Centroide(G),PS)$ 
	\ENDFOR
	\STATE $count = 1$
	\WHILE {$count \ne 0$}
		\STATE $count$ = $Quantidade(GS)$
		\STATE $Limpe(T)$
		\FORALL {$G$ em $GS$} 
			\STATE $P$ = Representante de $G$
			\FORALL {$e_i$ em $group$}
				\STATE $NearestP$ = $1NN(e_i, PS)$
				\STATE $Adicione((e_i,NearestP), T)$
			\ENDFOR
			\IF {$\forall$ $e_i, NearestP$ em $T$, $NearestPS$ = $P$}
				\STATE $count$ = $count - 1$
			\ELSIF {$\forall$ $e_i, NearestP$ em $T$, a $Classe(NearestP) \ne Classe(P)$} 
				\STATE $Vector = PrimeiraComponentePrincipal(G)$
				\STATE $Hiperplano$ = hiperplano que passa pelo centróide de $G$ e cujo vetor normal é a $Vector$.
				\STATE Divida $G$ em 2 grupos, instâncias acima e abaixo de $Hiperplano$
				\STATE Atualize $GS$ e $PS$.
			\ELSIF {$\exists$ $e_i, NearestP$ em $T$ tal que $NearestP \ne P$ e $Classe(NearestP) = Classe(P)$}
				\STATE Remova $e_i$ de $G$ e adicione a grupo de $NearestP$.
				\STATE Atualize $GPS$ e $PS$.
			\ELSIF {$\exists$ $e_i, NearestP$ em $T$ tal que o $Classe(NearestP) != Classe(P)$}
				\STATE Remova $e_i$ de $G$.
				\STATE Crie um novo grupo contendo as instâncias removidas.
				\STATE Atualize $PS$ e $GS$,
			\ENDIF
		\ENDFOR
	\ENDWHILE
	\RETURN  $PS$
\end{algorithmic}
\end{algorithm}

Observando o algoritmo do SGP1 \ref{alg:sgp1}, percebe-se que apesar do conceito ser bem simples, esta técnica possui alguns passos complexos, sendo necessário conhecimentos sobre extração de características [REFERÊNCIA PCA AQUI]. Principal Component Analysis é a técnica utilizada para traçar o vetor perpendicular ao hiperplano \ref{fig:divisaogrupossgp}.

A maior vantagem do SGP1 é que, conforme citado anteriormente, ele é não depende de parâmetros como quantidade de protótipos iniciais nem valores específicos. Por ser um algoritmo deterministico, o SGP1 executado numa mesma base de dados, sempre gerará os mesmos protótipos. Estes protótipos gerados possuem excelente representatividade do conjunto de treinamento, tanto que, utilizando-se os protótipos gerados como treinamento de um KNN, e classificando-se todas as instâncias de treinamento do SGP1, a taxa de acerto é de 100\%. Claro que o treinamento não pode ser utilizado para teste, mas isto mostra a boa representatividade das instâncias geradas pelo SGP1.

Porém, o SGP1 também apresenta desvantagens. Uma delas é que o SGP1 é muito custoso, exigindo, em geral, um treinamento mais longo que outras técnicas.

Outra desvantagem é que o SGP1 é sensível a ruídos, pois, se necessário, o algoritmo criará um grupo com apenas uma instância. No caso de um ruído, isto será muito desvantajoso, considerando que, em experimentos diversos, o SGP1 conseguiu reduzir em mais de 100 vezes o tamanho da base de dados.

Apesar das desvantagens citadas, bases desbalanceadas podem ser beneficiadas com o SGP1, considerando que ele considera os agrupamentos de classes, e não a quantidade de instâncias em cada classe.

\section{SGP 2}

O Self-Generating Prototypes 2 \cite{fayed:sgp}é uma versão melhorada do SGP1 que reduz ainda mais a quantidade de protótipos e é menos sensível aos ruídos e outliers. Para fazer essas melhorias, o SGP2 possui uma etapa de \textit{merge} e \textit{prunning}.

Quando dois grupos \textit{A} e \textit{B} são da mesma classe e para todas as instâncias de \textit{A} o segundo protótipo mais próximo é o representante de \textit{B}, e para todas as instâncias de \textit{B} o segundo protótipo mais próximo é o representante de \textit{A}, os grupos \textit{A} e \textit{B} podem ser fundidos, e será computado um novo protótipo para este novo grupo maior. Esta etapa é chamada de \textit{merge}, e ela é responsável por reduzir ainda mais a quantidade de protótipos do SGP1. O \textit{prunnig} consiste em  remover grupos onde o segundo protótipo mais próximo de todos os padrões de um certo grupo possuem a mesma classe, neste caso, tanto as instâncias quanto o representante do grupo são eliminados.

	Para evitar o sobre-ajuste e perda de generalização introduziu-se dois parâmetros ao SGP2 chamados de $R_n$ e $R_s$. O $R_n$ representa um limite para o tamanho relativo de um grupo em relação ao maior grupo. Por exemplo, se $R_n$ é 0.1 e o tamanho do maior grupo é 200, todos os grupos com tamanho menor que $20 (0.1 \times 200)$ são descartados. O segundo parâmetro $R_s$ é um limiar para a taxa de classificações incorretas de um grupo. Se o número de padrões classificados erroneamentes em um grupo dividido pelo tamanho do grupo é menor que $R_s$, então o grupo permanece inalterado. Este parâmetros reduzem o número de protótipos e aumentam a capacidade de generalização. Pereira e Cavalcanti recomendam  $0.01 < R_n < 0.2$ e $0.01 < R_s < 0.2$ \cite{csp:sgp}.

\begin{algorithm}[H][h]
\caption{SGP 2}
\label{alg:sgp2}
\begin{algorithmic}[1]
\REQUIRE {$PS$: uma lista para os representantes}
\REQUIRE {$GS$: uma lista de grupos de instâncias}
\REQUIRE {$T$: uma lista de duplas de instâncias}
	\FORALL {classe $C$}
		\STATE $G$ = $\bigcup$ instâncias da classe $C$
		\STATE $Adicione(G, GS)$
		\STATE $Adicione(Centroide(G),PS)$ 
	\ENDFOR
	\STATE $count = 1$
	\WHILE {$count \ne 0$}
		\STATE $count$ = $Quantidade(GS)$
		\STATE $Limpe(T)$
		\FORALL {$G$ em $GS$} 
			\STATE $P$ = Representante de $G$
			\FORALL {$e_i$ em $group$}
				\STATE $NearestP$ = $1NN(e_i, PS)$
				\STATE $Adicione((e_i,NearestP), T)$
			\ENDFOR
			\IF {Quantidade de tuplas em $T$ onde $NearestP \ne P$ $\le$ $R_s$}
				\STATE $count$ = $count - 1$
			\ELSIF {$\forall$ $e_i, NearestP$ em $T$, a $Classe(NearestP) \ne Classe(P)$} 
				\STATE $Vector = PrimeiraComponentePrincipal(G)$
				\STATE $Hiperplano$ = hiperplano que passa pelo centróide de $G$ e cujo vetor normal é a $Vector$.
				\STATE Divida $G$ em 2 grupos, instâncias acima e abaixo de $Hiperplano$
				\STATE Atualize $GS$ e $PS$.
			\ELSIF {$\exists$ $e_i, NearestP$ em $T$ tal que $NearestP \ne P$ e $Classe(NearestP) = Classe(P)$}
				\STATE Remova $e_i$ de $G$ e adicione a grupo de $NearestP$.
				\STATE Atualize $GPS$ e $PS$.
			\ELSIF {$\exists$ $e_i, NearestP$ em $T$ tal que o $Classe(NearestP) != Classe(P)$}
				\STATE Remova $e_i$ de $G$.
				\STATE Crie um novo grupo contendo as instâncias removidas.
				\STATE Atualize $PS$ e $GS$,
			\ENDIF
		\ENDFOR
	\ENDWHILE
	\STATE $LargeGroupCount$ = Quantidade de instâncias do maior grupo em $GS$
	\FORALL {$G$, $P$ in $GS$, $PS$}
		\STATE $CurrentGroupCount$ = Quantidade de instâncias de $G$.
		\IF {$CurrentGroupCount / LargeGroupCount \leq R_n$} %Warning Here
			\STATE Remova $G$ de $GS$ e $P$ de $PS$.
		\ENDIF	
	\ENDFOR
	\RETURN $PS$
\end{algorithmic}
\end{algorithm}

O algoritmo SGP2 \ref{alg:sgp2} é mais custoso e demorado que o SGP1, porém, em experimentos práticos, o SGP2 se mostrou mais eficiente, diminuindo a quantidade de protótipos ainda mais que o SGP1 e ainda assim, aumentando a taxa de acerto.

Porém, um defeito do SGP2 é que ele não leva em conta bases desbalanceadas. Dependendo da distribuição das instâncias, pode acontecer de, na fase de \textit{prunning} o SGP2 remover o representante da classe minoritária, podendo até remover todos os protótipos desta classe. Isto é perceptível, considerando o valor de $R_n = 0.15$, bases onde a classe minoritária possui apenas 3\% das instâncias da base, mesmo com a base marjoritária multimodal, provavelmente, após o \textit{prunning}, todos os protótipos serão da classe marjoritária.



