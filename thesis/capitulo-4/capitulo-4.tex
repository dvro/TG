% !TEX encoding = ISO-8859-1
\chapter{Bases Reais}
\label{ch:experimentobasesreais}

Neste capítulo serão mostrados experimentos feitos com bases reais. As bases utilizadas foram algumas das utilizadas por Fernández em seu estudo \textit{Sistemas de classificação baseados em fuzzy hierárquico com regra de seleção genética para bases desbalanceadas}\cite{FJH2009}.

Estas bases reais foram obtidas como parte do software KEEL, que contém um módulo de experimentos em bases desbalanceadas. Para todos os experimentos foi utilizado \textit{K-Fold Cross-Validation}, com 5 folds, respeitando a proporção das classes em todas as divisões, formato já fornecido junto com o software.


\section{Iris 0}

A base Iris0 é uma base com baixo desbalanceamento. Esta base contém 150 instâncias, cada uma contendo quatro atributos, sendo 33.33\% destas instâncias da classe minoritária, \textit{Iris-Setosa}, e 66.66\% da classe marjoritária, \textit{reminder}.


\begin{table}[H]\tiny
\begin{center}
\begin{tabular}{|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|}
\hline
Técnica		   				&	KNN		&	ENN		&		CNN		&	Tomek Links		&	OSS	&	LVQ 1	&	LVQ 2.1	&	LVQ 3	&	SGP	&	SGP 2 	\\
\hline %----- linha horizontal
Acerto Total				& 100.00 $\pm$ 0.00 \%	& 100.00 $\pm$ 0.00 \%& 67.39 $\pm$ 2.31 \%& 100.00 $\pm$ 0.00 \%& 84.18 $\pm$ 27.88 \%& 99.31 $\pm$ 1.54 \%& 99.31 $\pm$ 1.54 \%& 99.31 $\pm$ 1.54 \%& 98.64 $\pm$ 1.86 \%& 98.64 $\pm$ 1.86 \% \\
\hline
Acerto Marjoritária			& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 76.00 $\pm$ 42.63 \%& 98.95 $\pm$ 2.35 \%& 98.95 $\pm$ 2.35 \%& 98.95 $\pm$ 2.35 \%& 97.95 $\pm$ 2.81 \%& 97.95 $\pm$ 2.81 \% \\
\hline
Acerto Minoritária		    & 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 0.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \% \\
\hline
Tamanho Resultante			& 100.00 $\pm$ 0.00 \%& 100.00 $\pm$ 0.00 \%& 2.55 $\pm$ 0.02 \%& 100.00 $\pm$ 0.00 \%& 34.18 $\pm$ 0.79 \%& 8.50 $\pm$ 0.06 \%& 8.50 $\pm$ 0.06 \%& 8.50 $\pm$ 0.06 \%& 1.70 $\pm$ 0.01 \%& 1.70 $\pm$ 0.01 \% \\
\hline
\end{tabular}%--- fechaoento do aobiente tabular
\end{center}   %fio da centralização da tabela
\caption{Tabela do Iris 0}
\label{tab:iris}
\end{table}

Observando a tabela \ref{tab:iris}, pode-se observar que o KNN obteve 100\% de acerto, isso mostra que as classes tem um baixo nível de sobreposição. Se tratando de uma base com baixo nível de desbalanceamento e com agrupamentos bem definidos, é de se esperar que as técnicas gerem poucos protótipos para representar esta base. 

No caso do ENN, a taxa de acerto foi a mesma do KNN porque o seu algoritmo selecionou todas as instâncias, assim, quando as classes estão bem separadas, o ENN não é uma técnica apropriada, por conta do seu baixo poder de redução. Já o CNN, de alto poder de redução, reduziu demais a classe minoritária, levando a uma taxa de acerto média de 0.00\% para esta classe, enquanto a marjoritária obteve 100\% de acerto.

O Tomek Links, assim como o ENN, não fez diferença nesta base, pois, conforme citado e comprovado anteriormente, o Tomek Links atua apenas nas regiões de indecisão, e a base Iris0 não apresenta esta região.

O OSS, técnica utilizada para abses desbalanceadas, obteve uma taxa de acerto total média de 84.18\% em média, uma taxa de acerto baixa em relação as outras técnicas. A redução também não foi tão alta, a quantidade de protótipos resultantes foi em média 34.18\% da baso original. Porém, como o \textit{One-Sided Selection} dá prioridade a classe minoritária, pode-se observar que a taxa de acerto desta classe foi de 100\%, o que torna esta uma técnica eficiente quando o caso de interesse é a classe minoritária.

O LVQ 1, 2.1 e 3 não tiveram diferença, provavelmente isso se deve ao fato de as classes estarem bem separadas. Uma característica interessante é que as versões do \textit{Learning-Vector Quantization} obtiveram quase 99.31\% de acerto total, sendo a taxa de acerto para classe minoritária de 100\%. Isso comprova o que foi dito no capítulo anterior, o LVQ é eficiente para bases desbalanceadas, principalmente quando as classes estão bem separadas. O poder de redução desta classe também tem um bom desempenho, visto que é possível escolher a quantidade de protótipos finais, assim como corrigir o desbalanceamento.

Como a base Iris0 possui baixo nível de desbalanceamento, as duas versões do \textit{Self-Generating Prototypes} obtiveram um excelente desempenho. A taxa de acerto geral para ambas foi de 98.64\%, uma excelente taxa, considerando que a quantidade de protótipos resultante foi de 1.70\% do conjunto de treinamento original. Esta técnica possui um alto poder de redução, e nesta abse, a taxa de acerto da classe minoritária foi de 100\%.

Não houve diferença entre o SGP1 e SGP2, pois a separação entre as classes tornou os passos de $Merge$ e $Pruning$ desnecessários.


\section{Glass 5}

A base Glass5 é uma base com alto desbalanceamento. Esta base contém 214 instâncias, cada uma contendo nove atributos. Apenas 4.20\% das instâncias são da classe minoritária, \textit{tableware}, e 95.80\% da classe marjoritária, \textit{reminder}.


\begin{table}[H]\tiny
\begin{center}
\begin{tabular}{|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|}
\hline
Técnica		    &KNN&ENN&CNN&Tomek Links&OSS&LVQ 1&LVQ 2.1&LVQ 3&SGP&SGP 2 \\
\hline %----- linha horizontal
Acerto Total		    & 96.28 $\pm$ 3.53 \%& 95.81 $\pm$ 2.55 \%& 95.80 $\pm$ 1.02 \%& 96.28 $\pm$ 3.53 \%& 85.53 $\pm$ 15.62 \%& 80.35 $\pm$ 4.65 \%& 81.28 $\pm$ 5.81 \%& 81.30 $\pm$ 5.98 \%& 95.80 $\pm$ 1.93 \%& 95.80 $\pm$ 1.93 \% \\
\hline
Acerto Marjoritária		   & 98.05 $\pm$ 3.18 \%& 99.02 $\pm$ 2.18 \%& 100.00 $\pm$ 0.00 \%& 98.05 $\pm$ 3.18 \%& 86.83 $\pm$ 16.60 \%& 80.98 $\pm$ 5.56 \%& 81.95 $\pm$ 6.36 \%& 81.46 $\pm$ 6.59 \%& 99.51 $\pm$ 1.09 \%& 99.51 $\pm$ 1.09 \% \\
	\hline
Acerto Minoritária		    & 60.00 $\pm$ 41.83 \%& 30.00 $\pm$ 44.72 \%& 0.00 $\pm$ 0.00 \%& 60.00 $\pm$ 41.83 \%& 60.00 $\pm$ 41.83 \%& 60.00 $\pm$ 54.77 \%& 60.00 $\pm$ 54.77 \%& 70.00 $\pm$ 44.72 \%& 10.00 $\pm$ 22.36 \%& 10.00 $\pm$ 22.36 \% \\
\hline
Tamanho Resultante		     & 100.00 $\pm$ 0.00 \%& 95.78 $\pm$ 1.13 \%& 7.86 $\pm$ 1.24 \%& 99.30 $\pm$ 0.64 \%& 10.67 $\pm$ 0.88 \%& 5.86 $\pm$ 0.03 \%& 5.86 $\pm$ 0.03 \%& 5.86 $\pm$ 0.03 \%& 3.17 $\pm$ 1.59 \%& 1.64 $\pm$ 1.46 \% \\
\hline
\end{tabular}%--- fechaoento do aobiente tabular
\end{center}   %fio da centralização da tabela
\caption{Tabela do Glass 5}
\label{tab:glass}
\end{table}


Observando a tabela \ref{tab:glass}, percebe-se que, neste exemplo, além de a base ser mais desbalanceada, existe uma maior sobreposição de classes que o exemplo anterior. Em geral, as técnicas obtiveram uma boa taxa de acerto geral, mas a taxa de acerto da classe minoritária variou muito de acordo com a técnica.

Como a base Glass 5 apresenta sobreposição de classes, o ENN gerou uma pequena redução de instâncias, reduzindo para 95.78\% em média. Porém, a taxa de acerto da classe minoritária foi muito pequena em relação a marjoritária. o ENN obteve uma taxa média de 30\% de acerto e desvio padrão foi de 44.72\% na classe minoritária, assim, conforme comprovado nas bases artificiais, quando existe uma maior sobreposição, a classe minoritária é muito reduzida, compromentendo grandemente o desempenho do classificador para esta classe.

Já o CNN conseguiu reduzir consideravelmente o número de instâncias, mas sua taxa de acerto para bases desbalanceadas foi praticamente nula. Isso confirma o que foi visto na base Iris 0, o CNN não é uma técnica eficiente para bases desbalanceadas, principalmente com alto nível de desbalanceamento. Com a modificação do CNN usada pelo OSS, a taxa de acerto seria melhorada, mas a técnica tradicional mais uma vez não se mostrou apropriada para o caso de estudo.

O Tomek Links conseguiu uma boa taxa de acerto média, 96.28\%, se comparado com as técnicas anteriores. A taxa de acerto da classe minoritária foi de 60\%. Se comparado com o KNN, observa-se que o Tomek Links foi eficiente para classificar bases desbalanceadas, mas isso aconteceu porque o Tomek Links praticamente não alterou a base de dados, sendo a quantidade de protótipos selecionados 99.30\% do conjunto de treinamento original. Com isso, conclui-se que o Tomek Links é eficiente na remoção de instâncias na região de indecisão, porém, nem sempre a região de indecisão é significativa em relação a original, assim, recomenda-se o uso de sua versão adaptada como pré-processamento.

O OSS, obteve uma taxa de acerto total inferior as técnicas citadas anteriormente, sendo 85.53\% em média. Todavia, observa-se que a taxa de acerto da base minoritária foi de 60\%, a mesma taxa do KNN e, diferentemente do Tomek Links, a quantidade de protótipos selecionados pelo OSS foi em médi apenas 10.67\% do conjunto de treinamento original. Isso mostra que, mesmo com um nível de desbalanceamento maior, \textit{One-Sided Selection} tem um alto poder de redução e prioriza a classe minoritária.

As versões do LVQ tiveram desempenho parecido, porém, o LVQ 3 se mostrou mais eficiente para a classe minoritária. Observando os experimentos do capítulo anterior, percebe-se que, neste experimento, o espalhamento controlado dos protótipos resultou em um percentual de 10\% de acerto maior que as outras versões do LVQ. Em relação as técnicas anteriores, o LVQ teve um alto nível de redução da base, apenas 5.86\% de instâncias foram necessárias para ter a mesma taxa de acerto da classe minoritária que o próprio KNN.

O \textit{Learning Vector Quantization} é uma técnica eficiente, e percebe-se que, ao diminuir o desbalanceamento de classes, esta técnica beneficia casos onde a classe minoritária é o caso de interesse e, ainda assim, não compromete, consideravelmente, a taxa de acerto da classe marjoritária.


O \textit{Self-Generating Prototypes 1} foi altamente ineficiente em classificar a classe minoritária. A tabela \ref{tab:glass} mostra que o SGP 1 reduziu a base de dados para 3.17\% do conjunto de treinamento original, mas o custo disso foi uma taxa de acerto média de apenas 10\% para classe minoritária. No caso da Iris 0, como existia um baixo nível de desbalanceamento o SGP foi eficiente, porém, com uma base mais desbalanceada, esta técnica removou a maioria das instâncias da classe minoritária, tornando os protótipos resultantes inviáveis para qualquer classificador.


A segunda versão do SGP teve o mesmo comportamento que o SGP 1, porém, o reduziu a base para 1.64\%. Esta redução seria interessante, caso o SGP 1 tivesse tido um bom desempenho, mas, como não foi o caso, o SGP 2 também se mostrou inviável.


\section{Yeast 6}

A base Yesat 6 é a base de mais alto nível de desbalanceamento estudada neste trabalho. Esta base contém 1484 instâncias, cada uma contendo 8 atributos. Apenas 2.49\% das instâncias são da classe minoritária, \textit{exc}, e 97.51\% da classe marjoritária, \textit{reminder}.

\begin{table}[H]\tiny
\begin{center}
\begin{tabular}{|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|@{}l@{}|}
\hline
Técnica		    &KNN&ENN&CNN&Tomek Links&OSS&LVQ 1&LVQ 2.1&LVQ 3&SGP&SGP 2 \\
\hline %----- linha horizontal
Acerto Total		    & 97.63 $\pm$ 0.96 \%& 98.04 $\pm$ 0.81 \%& 97.29 $\pm$ 1.35 \%& 97.90 $\pm$ 0.94 \%& 96.41 $\pm$ 1.28 \%& 86.86 $\pm$ 2.15 \%& 87.07 $\pm$ 2.18 \%& 87.13 $\pm$ 2.45 \%& 97.77 $\pm$ 0.91 \%& 97.36 $\pm$ 0.80 \% \\
\hline
Acerto Marjoritária		   & 98.96 $\pm$ 0.49 \%& 99.44 $\pm$ 0.53 \%& 98.41 $\pm$ 1.31 \%& 99.10 $\pm$ 0.53 \%& 97.16 $\pm$ 0.93 \%& 86.82 $\pm$ 2.21 \%& 87.03 $\pm$ 2.25 \%& 87.10 $\pm$ 2.55 \%& 98.96 $\pm$ 0.65 \%& 98.54 $\pm$ 0.45 \% \\
\hline
Acerto Minoritária		    & 42.86 $\pm$ 22.59 \%& 40.00 $\pm$ 23.47 \%& 51.43 $\pm$ 12.78 \%& 48.57 $\pm$ 23.90 \%& 65.71 $\pm$ 16.29 \%& 88.57 $\pm$ 11.95 \%& 88.57 $\pm$ 11.95 \%& 88.57 $\pm$ 11.95 \%& 48.57 $\pm$ 25.95 \%& 48.57 $\pm$ 32.89 \% \\
\hline
Tamanho Resultante		     & 100.00 $\pm$ 0.00 \%& 97.94 $\pm$ 0.30 \%& 6.44 $\pm$ 0.74 \%& 98.80 $\pm$ 0.24 \%& 8.46 $\pm$ 1.01 \%& 0.86 $\pm$ 0.00 \%& 0.86 $\pm$ 0.00 \%& 0.86 $\pm$ 0.00 \%& 9.24 $\pm$ 1.66 \%& 4.66 $\pm$ 0.80 \% \\
\hline
\end{tabular}%--- fechaoento do aobiente tabular
\end{center}   %fio da centralização da tabela
\caption{Tabela do Yeast 6}
\label{tab:yeast}
\end{table}


A base Yast 6 é de mais alto nível de desbalanceamento e será o referencial para casos extremos neste trabalho.

Observando a tabela \ref{tab:yeast} percebe-se que o KNN teve uma taxa de acerto alta, porém, a taxa de acerto da classe minoritária foi em média apenas 42.86\%.

O ENN reduziu a base de dados para 97.94\% e aumentou a taxa de acerto geral para 98.04\%, mas o custo disso foi a redução da taxa de acerto da classe minoritária em 2.86\% em média. Neste caso, percebe-se que esta técnica foi ineficiente, pois removeu instâncias significativas da classe minoritária.

Já o CNN, por manter instâncias da região de fronteira e, neste caso, praticamente todas as instâncias da classe minoritária, foi eficiente. Os protótipos selecionados por esta técnica foram apenas 6.44\% do conjunto de treinamento, ou seja, diminuiu consideravelmente o custo e o tempo de processamento. Além desta redução, o CNN teve um aumento de 8.57\% na taxa de acerto da classe minoritária em relação ao KNN.

Com os fatos citados acima, pode-se concluir que o CNN se mostrou eficiente. Neste caso, pode-se dizer que as instâncias da classe minoritária estão distribuídas e a maioria das instâncias desta classe foram selecionadas. Ou seja, para o uso do CNN, é importante que a classe minoritária esteja bem distribuída para que mais instâncias desta classe sejam selecionadas.

O Tomek Links, apesar de também remover instâncias da classe minoritária, apresentou uma melhora em relação ao KNN. Esta técnica apresentou um ganho de 5.71\% na taxa de acerto da classe minoritária em média. O desevio padrão, porém, mostra que houve casos onde a taxa de acerto foi inferior a 30\%, ou seja, o Tomek Links deve ser utilizado apenas quando a quantidade de instâncias removidas não será significativa para a classificação.

O OSS se mostrou a técnica seletiva mais eficiente. Por utilizar o CNN modificado o nível de desbalanceamento foi reduzido e o Tomek Links modificado deixou a classe minoritária bem definida, assim, a taxa de acerto da classe minoritária foi de 65.71\%, o que representa um aumento de 22.85\% em relação ao KNN. Mais uma vez, o OSS se mostrou eficiente independente do nível de desbalanceamento e sobreposição de classes.

Entre as versões do LVQ não houve diferença relevante. Mesmo neste caso extremo o LVQ teve uma taxa de acerto média de 88.57\%, sendo superior ao OSS. Isso mostra que, como o LVQ elimina o desbalanceamento, a classe minoritária é extremamente beneficiada. Outra vantagem do LVQ é a redução de instâncias, nesta base, a quantidade de protótipos foi apenas 0.86\% do conjunto de treinamento.

O SGP 1 teve um bom desempenho se comparado com o KNN. A taxa de acerto da classe minoritária foi de 48.57\%, isso é, um aumento de 5.71\% em relação ao KNN. Além disso, os protótipos criados por esta técnica foram apenas 9.24\% do conjunto original. Porém, se comparado com o LVQ, percebe-se que o SGP teve uma redução baixa e não priorizou a classe minoritária. Na base Yast 6, o SGP 2 teve o mesmo desempenho que o SGP, porém, reduziu a base para 4.66\% do conjunto de treinamento original.

Apesar de terem um bom desempenho médio nesta base, as duas versões do SGP não são recomendadas em bases desbalanceadas. Em alguns folds, o SGP 2 teve uma taxa de acerto da classe minoritária inferior a 25\%, isso aconteceu porque neste fold, as instâncias não ficaram agrupadas, e foram totalmente eliminadas na aplicação do fator de generalização.


