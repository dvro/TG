% !TEX encoding = ISO-8859-1
\chapter{Bases Reais}
\label{ch:experimentobasesreais}

Neste capítulo serão mostrados experimentos feitos com bases reais. As bases selecionadas foram algumas das utilizadas por Fernández em seu estudo \textit{Sistemas de classificação baseados em fuzzy hierárquico com regra de seleção genética para bases desbalanceadas}\cite{FJH2009}.

Estas bases reais foram obtidas do software KEEL, que contém um módulo de experimentos em bases desbalanceadas. Para todos os experimentos foi utilizado \textit{K-Fold Cross-Validation}, com 5 folds, formato já fornecido pelo software.


\section{Iris 0}

	A base Iris 0 é uma base com baixo desbalanceamento. Esta base contém 150 instâncias, cada uma contendo quatro atributos, sendo 33.33\% destas instâncias da classe minoritária, \textit{Iris-Setosa}, e 66.66\% da classe marjoritária, \textit{reminder}.


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Técnica     &  Acerto Total &  Acerto Marjoritária &  Acerto Minoritária  &  Tamanho Resultante  \\
\hline
 KNN   &      100.00 $\pm$ 0.00 \%   &    100.00 $\pm$ 0.00 \%   &    100.00 $\pm$ 0.00 \%    &    100.00 $\pm$ 0.00 \%  \\
\hline
 ENN   &     100.00 $\pm$ 0.00 \%   &    100.00 $\pm$ 0.00 \%   &    100.00 $\pm$ 0.00 \%    &    100.00 $\pm$ 0.00 \%  \\
\hline
 CNN   &     45.94 $\pm$ 19.05 \%   &    40.00 $\pm$ 54.77 \%   &    60.00 $\pm$ 54.77 \%    &    2.04 $\pm$ 0.48 \%  \\
\hline
 Tomek Links   &     100.00 $\pm$ 0.00 \%   &    100.00 $\pm$ 0.00 \%   &    100.00 $\pm$ 0.00 \%    &    100.00 $\pm$ 0.00 \%  \\
\hline
 OSS   &     56.33 $\pm$ 33.73 \%   &    35.89 $\pm$ 49.15 \%   &    100.00 $\pm$ 0.00 \%    &    33.84 $\pm$ 0.50 \%  \\
\hline
 LVQ 1   &     99.31 $\pm$ 1.54 \%   &    98.95 $\pm$ 2.35 \%   &    100.00 $\pm$ 0.00 \%    &    8.50 $\pm$ 0.06 \%  \\
\hline
 LVQ 2.1   &     99.31 $\pm$ 1.54 \%   &    98.95 $\pm$ 2.35 \%   &    100.00 $\pm$ 0.00 \%    &    8.50 $\pm$ 0.06 \%  \\
\hline
 LVQ 3   &     99.31 $\pm$ 1.54 \%   &    98.95 $\pm$ 2.35 \%   &    100.00 $\pm$ 0.00 \%    &    8.50 $\pm$ 0.06 \%  \\
\hline
 SGP   &     98.64 $\pm$ 1.86 \%   &    97.95 $\pm$ 2.81 \%   &    100.00 $\pm$ 0.00 \%    &    1.70 $\pm$ 0.01 \%  \\
\hline
 SGP 2   &     98.64 $\pm$ 1.86 \%   &    97.95 $\pm$ 2.81 \%   &    100.00 $\pm$ 0.00 \%    &    1.70 $\pm$ 0.01 \%  \\
\hline
\end{tabular}%%--- fechamento do ambiente tabular
\end{center}   %%fim da centralização da tabela
\caption{Tabela do Iris 0}
\label{tab:iris}
\end{table}

Observando a tabela \ref{tab:iris}, percebe-se que o KNN obteve 100\% de acerto, isso mostra que as classes tem um baixo nível de sobreposição. Se tratando de uma base com baixo nível de desbalanceamento e com agrupamentos bem definidos, é de se esperar que as técnicas gerem poucos protótipos para representar esta base. 

No caso do ENN, a taxa de acerto foi a mesma do KNN porque o seu algoritmo selecionou todas as instâncias, assim, quando as classes estão bem separadas, o ENN não é uma técnica apropriada, por conta do seu baixo poder de redução. 

Por sua vez o CNN, de alto poder de redução, reduziu demais a classe minoritária, mas como foi utilizado o 3-NN, obteve taxa de acerto média de 60.00\%, com casos de quase 0.00\% para esta classe.

O Tomek Links, assim como o ENN, não fez diferença nesta base, pois, conforme citado e comprovado anteriormente, o Tomek Links atua apenas nas regiões de indecisão, e a base Iris 0 não apresenta esta região.


\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/graficos/grafico1_iris.eps}
\caption{Taxa de acerto da classe minoritária por técnica na base Iris}
\label{fig:iris1}
\end{figure}

O OSS, técnica utilizada para bases desbalanceadas, obteve uma taxa de acerto total de 56.33\% em média, uma taxa de acerto baixa em relação as outras técnicas. A redução também não foi tão alta, a quantidade de protótipos resultantes foi em média 33.84\% da baso original. Porém, como o \textit{One-Sided Selection} dá prioridade a classe minoritária, pode-se observar que a taxa de acerto desta classe foi de 100\%, o que torna esta uma técnica eficiente quando o caso de interesse é a classe minoritária.

O LVQ 1, 2.1 e 3 não tiveram diferença entre si, provavelmente isso se deve ao fato de as classes estarem bem separadas. Uma característica interessante é que as versões do \textit{Learning-Vector Quantization} obtiveram 99.31\% de acerto total, sendo a taxa de acerto para classe minoritária de 100\%. Isso comprova o que foi dito no capítulo anterior, o LVQ é eficiente para bases desbalanceadas, principalmente quando as classes estão bem separadas. O poder de redução desta classe também tem um bom desempenho, visto que é possível escolher a quantidade de protótipos finais, assim como corrigir o desbalanceamento.

Como a base Iris 0 possui baixo nível de desbalanceamento, as duas versões do \textit{Self-Generating Prototypes} obtiveram um excelente desempenho. A taxa de acerto geral para ambas foi de 98.64\%, uma excelente taxa, considerando que a quantidade de protótipos resultante foi de 1.70\% do conjunto de treinamento original. Esta técnica possui um alto poder de redução, e nesta base, a taxa de acerto da classe minoritária foi de 100\%.

Não houve diferença entre o SGP1 e SGP2, pois a separação entre as classes tornou os passos de $Merge$ e $Pruning$ desnecessários.

\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/graficos/grafico2_iris.eps}
\caption{Tamanho a base de dados após seleção de protótipos na base Iris}
\label{fig:iris2}
\end{figure}

Nesta base, com baixa sobreposição de classes, o ENN e o Tomek Links foram inúteis, pois não apresentaram redução de dados. Já o CNN se mostrou altamente ineficiente (ver figura \ref{fig:iris1}), pois reduziu tanto a classe minoritária que tornou a taxa de acerto desta classe baixa, pois foi utilizado K=3, e houve casos em que apenas 1 protótipo foi selecionado.

Com este experimento, conclui-se também que, em bases com baixo nível de desbalanceamento e boa separação entre as classes, as versões do \textit{Self-Generating Prototypes} são eficientes e possuem um alto poder de redução. Porém, técnicas como o \textit{Learning-Vector Quantization} podem ser ainda mais eficientes, principalmente com a escolha adequada de parâmetros, além de não correr risco de eliminação da classe minoritária.

Outra técnica apropriada para este tipo de base foi o \textit{One-Sided Selection}. Por priorizar a classe minoritária, o OSS garante uma boa taxa de acerto para esta classe. Porém, comparando esta técnica como o SGP e LVQ, percebe-se que ela tem um baixo nível de redução (ver figura \ref{fig:iris2}), sendo recomendado a aplicação de outra técnica após o OSS.


\section{Glass 5}

A base Glass 5 é uma base com alto desbalanceamento. Esta base contém 214 instâncias, cada uma contendo nove atributos. Apenas 4.20\% das instâncias são da classe minoritária, \textit{tableware}, e 95.80\% da classe marjoritária, \textit{reminder}.

Observando a tabela \ref{tab:glass}, percebe-se que, neste exemplo, além de a base possuir um maior deslanceamento, existe uma maior sobreposição de classes que o exemplo anterior. Em geral, as técnicas obtiveram uma boa taxa de acerto total, mas a taxa de acerto da classe minoritária variou muito de acordo com a técnica.

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Técnica     &  Acerto Total &  Acerto Marjoritária &  Acerto Minoritária  &  Tamanho Resultante  \\
\hline
 KNN   &      96.28 $\pm$ 3.53 \%   &    98.05 $\pm$ 3.18 \%   &    60.00 $\pm$ 41.83 \%    &    100.00 $\pm$ 0.00 \%  \\
\hline
 ENN   &     95.81 $\pm$ 2.55 \%   &    99.02 $\pm$ 2.18 \%   &    30.00 $\pm$ 44.72 \%    &    95.78 $\pm$ 1.13 \%  \\
\hline
 CNN   &     93.94 $\pm$ 5.83 \%   &    97.56 $\pm$ 5.45 \%   &    10.00 $\pm$ 22.36 \%    &    7.62 $\pm$ 1.19 \%  \\
\hline
 Tomek Links   &     96.28 $\pm$ 3.53 \%   &    98.05 $\pm$ 3.18 \%   &    60.00 $\pm$ 41.83 \%    &    99.30 $\pm$ 0.64 \%  \\
\hline
 OSS   &     78.58 $\pm$ 20.54 \%   &    79.02 $\pm$ 22.79 \%   &    70.00 $\pm$ 44.72 \%    &    10.43 $\pm$ 1.35 \%  \\
\hline
 LVQ 1   &     80.82 $\pm$ 6.55 \%   &    81.95 $\pm$ 6.36 \%   &    50.00 $\pm$ 50.00 \%    &    5.86 $\pm$ 0.03 \%  \\
\hline
 LVQ 2.1   &     80.82 $\pm$ 6.55 \%   &    81.95 $\pm$ 6.36 \%   &    50.00 $\pm$ 50.00 \%    &    5.86 $\pm$ 0.03 \%  \\
\hline
 LVQ 3   &     81.30 $\pm$ 6.20 \%   &    82.44 $\pm$ 6.07 \%   &    50.00 $\pm$ 50.00 \%    &    5.86 $\pm$ 0.03 \%  \\
\hline
 SGP   &     95.80 $\pm$ 1.93 \%   &    99.51 $\pm$ 1.09 \%   &    10.00 $\pm$ 22.36 \%    &    3.17 $\pm$ 1.59 \%  \\
\hline
 SGP 2   &     95.80 $\pm$ 1.93 \%   &    99.51 $\pm$ 1.09 \%   &    10.00 $\pm$ 22.36 \%    &    1.64 $\pm$ 1.46 \%  \\
\hline
\end{tabular}%%--- fechamento do ambiente tabular
\end{center}   %%fim da centralização da tabela
\caption{Tabela do Glass 5}
\label{tab:glass}
\end{table}


Como a base Glass 5 apresenta sobreposição de classes, o ENN gerou uma pequena redução de instâncias, reduzindo para 95.81\% em média. Porém, a taxa de acerto da classe minoritária foi muito pequena em relação a marjoritária. O ENN obteve uma taxa média de 30\% de acerto e desvio padrão foi de 44.72\% na classe minoritária, assim, conforme comprovado nas bases artificiais, quando existe uma maior sobreposição, a classe minoritária é muito reduzida, compromentendo grandemente o desempenho do classificador para esta classe.

Já o CNN conseguiu reduzir consideravelmente o número de instâncias, mas sua taxa de acerto para a classe minoritária foi de apenas 10\%, havendo casos onde foi praticamente nula. Isso confirma o que foi visto na base Iris 0, o CNN não é uma técnica eficiente para bases desbalanceadas, principalmente com alto nível de desbalanceamento. Com a modificação do CNN usada pelo OSS, a taxa de acerto seria melhorada, mas a técnica tradicional mais uma vez não se mostrou apropriada para o caso de estudo. Se fosse utilizado K=1 para o KNN, a taxa de acerto seria superior, mas isso deixaria o classificador mais sensível a ruídos.


\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/graficos/grafico1_glass.eps}
\caption{Taxa de acerto da classe minoritária por técnica na base Glass 5}
\label{fig:glass1}
\end{figure}


O Tomek Links conseguiu uma boa taxa de acerto média, 96.28\%, se comparado com as técnicas anteriores. A taxa de acerto da classe minoritária foi de 60\%. Ao comparar com o KNN, observa-se que o Tomek Links foi eficiente para classificar bases desbalanceadas, mas isso aconteceu porque seu algoritmo praticamente não alterou a base de dados, sendo a quantidade de protótipos selecionados 99.30\% do conjunto de treinamento original. 

Neste caso, o Tomek Links teve um bom desempenho, removendo a região de indecisão, mas pode acontecer de seu algoritmo remover todas as instâncias da classe minoritária. Assim, recomenda-se o uso de sua versão adaptada como pré-processamento, para evitar a extinção desta classe.

O OSS, obteve uma taxa de acerto total inferior as demais técnicas, sendo 78.58\% em média. Todavia, observa-se que a taxa de acerto da base minoritária foi de 70\%, o melhor desempenho nesta base (ver figura \ref{fig:glass1}). 

A quantidade de protótipos selecionados pelo OSS foi em média apenas 10.43\% do conjunto de treinamento original. Isso mostra que, mesmo com um alto nível de desbalanceamento, o \textit{One-Sided Selection} tem um poder de redução relativamente eficiente, priorizando a classe minoritária.


\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/graficos/grafico2_glass.eps}
\caption{Tamanho a base de dados após seleção de protótipos na base Glass 5}
\label{fig:glass2}
\end{figure}


As versões do \textit{Learning Vector Quantization} foram eficientes em alguns folds. Analisando detalhandamente, Percebe-se que, ao diminuir o desbalanceamento de classes, esta técnica beneficia casos onde a classe minoritária é o caso de interesse e, ainda assim, não compromete consideravelmente a taxa de acerto da classe marjoritária.

O \textit{Self-Generating Prototypes 1} foi altamente ineficiente em classificar a classe minoritária. A tabela \ref{tab:glass} mostra que o SGP 1 reduziu a base de dados para 3.17\% do conjunto de treinamento original (ver figura \ref{fig:glass2}), mas o custo disso foi uma taxa de acerto média de apenas 10\% para classe minoritária (ver figura \ref{fig:glass1}). No caso da Iris 0, como existia um baixo nível de desbalanceamento o SGP foi eficiente, porém, com uma base mais desbalanceada, esta técnica removeu a maioria das instâncias da classe minoritária, tornando os protótipos resultantes inviáveis para qualquer classificador.

A segunda versão do SGP teve o mesmo comportamento que o SGP 1, porém, o reduziu a base para 1.64\%. Esta redução seria interessante, caso o SGP 1 tivesse tido um bom desempenho, mas como não foi o caso, o SGP 2 também se mostrou inviável.

Assim, conclui-se que, em bases com alto nível de desbalanceamento e com sobreposição de classes, as versões do SGP são inviáveis, principalmente quando o caso de interesse é a classe minoritária. Isso acontece porque o SGP não faz distinção entre classes. As demais técnicas se mostraram indiferentes ou inviáveis, dependendo do fold, exceto pelo OSS.

Da mesma forma que o experimento anterior, o OSS teve um excelente desempenho para classificar instâncias da classe minoritária, sendo recomendado mesmo com alto nível de desbalanceamento.


\section{Yeast 6}

A base Yesat 6 é a base de mais alto nível de desbalanceamento estudada neste trabalho. Esta base contém 1484 instâncias, cada uma contendo 8 atributos. Apenas 2.49\% das instâncias são da classe minoritária, \textit{exc}, e 97.51\% da classe marjoritária, \textit{reminder}. Esta base será o referencial de casos de extremo desbalanceamento neste trabalho.

Observando a tabela \ref{tab:yeast} percebe-se que o KNN teve uma taxa de acerto alta, porém, a taxa de acerto da classe minoritária foi em média apenas 42.86\%.

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
Técnica     &  Acerto Total &  Acerto Marjoritária &  Acerto Minoritária  &  Tamanho Resultante  \\
\hline
KNN	&	97.63 $\pm$ 0.96 \%	&	98.96 $\pm$ 0.49 \%	&	42.86 $\pm$ 22.59 \%	&	100.00 $\pm$ 0.00 \%	\\
\hline
ENN&	 98.04 $\pm$ 0.81 \%&	 99.44 $\pm$ 0.53 \%&	 40.00 $\pm$ 23.47 \%&	 97.94 $\pm$ 0.30 \%		\\
\hline
CNN&	 97.29 $\pm$ 1.35 \%&	 98.41 $\pm$ 1.31 \%&	 51.43 $\pm$ 12.78 \%&	 6.44 $\pm$ 0.74 \%		\\
\hline
Tomek Links&	 97.90 $\pm$ 0.94 \%&	 99.10 $\pm$ 0.53 \%&	 48.57 $\pm$ 23.90 \%&	 98.80 $\pm$ 0.24 \%	\\
\hline
OSS&	 96.41 $\pm$ 1.28 \%&	 97.16 $\pm$ 0.93 \%&	 65.71 $\pm$ 16.29 \%&	 8.46 $\pm$ 1.01 \%		\\
\hline
LVQ 1&	 86.86 $\pm$ 2.15 \%&	 86.82 $\pm$ 2.21 \%&	 88.57 $\pm$ 11.95 \%&	 0.86 $\pm$ 0.00 \%		\\
\hline
LVQ 2.1&	 87.07 $\pm$ 2.18 \%&	 87.03 $\pm$ 2.25 \%&	 88.57 $\pm$ 11.95 \%&	 0.86 $\pm$ 0.00 \%	\\
\hline
LVQ 3&	 87.13 $\pm$ 2.45 \%&	 87.10 $\pm$ 2.55 \%&	 88.57 $\pm$ 11.95 \%&	 0.86 $\pm$ 0.00 \%		\\
\hline
SGP&	 97.77 $\pm$ 0.91 \%&	 98.96 $\pm$ 0.65 \%&	 48.57 $\pm$ 25.95 \%&	 9.24 $\pm$ 1.66 \%		\\
\hline
SGP 2 &	 97.36 $\pm$ 0.80 \%&	 98.54 $\pm$ 0.45 \%&	 48.57 $\pm$ 32.89 \%&	 4.66 $\pm$ 0.80 \% 		\\
\hline
\end{tabular}%--- fechaoento do aobiente tabular
\end{center}   %fio da centralização da tabela
\caption{Tabela do Yeast 6}
\label{tab:yeast}
\end{table}

O ENN reduziu a base de dados para 97.94\% e aumentou a taxa de acerto geral para 98.04\%, mas o custo disso foi a redução da taxa de acerto da classe minoritária em 2.86\% em média. 

Já o CNN, por manter instâncias da região de fronteira e, neste caso foi eficiente. Os protótipos selecionados por esta técnica foram apenas 6.44\% do conjunto de treinamento, ou seja, diminuiu consideravelmente o custo e o tempo de processamento. Além desta redução, o CNN teve um aumento de 8.57\% na taxa de acerto da classe minoritária em relação ao KNN. Isso aconteceu por conta da disposição da classe minoritária em regiões de indecisão.

O Tomek Links, apesar de também remover instâncias da classe minoritária, apresentou uma melhora em relação ao KNN. Esta técnica apresentou um ganho de 5.71\% na taxa de acerto da classe minoritária em média. O desvio padrão, porém, mostra que houve casos onde a taxa de acerto foi inferior a 30\%, ou seja, o Tomek Links deve ser utilizado apenas quando a quantidade de instâncias removidas não será significativa para a classificação, ou seja, quando os Links não contém grande parte da classe minoritária.

\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/graficos/grafico1_yeast.eps}
\caption{Taxa de acerto da classe minoritária por técnica na base Yeast}
\label{fig:yeast1}
\end{figure}

O OSS se mostrou a técnica seletiva mais eficiente. Por utilizar o CNN modificado o nível de desbalanceamento foi reduzido e o Tomek Links modificado deixou a classe minoritária bem definida, assim, a taxa de acerto da classe minoritária foi de 65.71\%, o que representa um aumento de 22.85\% em relação ao KNN. Mais uma vez, o OSS se mostrou eficiente independente do nível de desbalanceamento e sobreposição de classes.

Entre as versões do LVQ não houve diferença relevante. Mesmo neste caso extremo o LVQ teve uma taxa de acerto média de 88.57\%, sendo superior ao OSS. Isso mostra que, como o LVQ elimina o desbalanceamento, a classe minoritária é extremamente beneficiada. Outra vantagem do LVQ é a redução de instâncias. A quantidade de protótipos criados para esta base foi apenas 0.86\% do conjunto de treinamento.

\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/graficos/grafico2_yeast.eps}
\caption{Tamanho a base de dados após seleção de protótipos na base Yeast}
\label{fig:yeast2}
\end{figure}


O SGP 1 teve um bom desempenho médio, se comparado com o KNN. A taxa de acerto da classe minoritária foi de 48.57\%, isso é, um aumento de 5.71\% em relação ao KNN. Além disso, os protótipos criados por esta técnica foram apenas 9.24\% do conjunto original. Porém, se comparado com o LVQ, percebe-se que o SGP teve uma redução baixa e não priorizou a classe minoritária, pois houveram folds onde a taxa de acerto desta classe foi inferior a 25\%.

Na base Yast 6, o SGP 2 teve o mesmo desempenho que o SGP no que se refere a taxa de acerto. Porém, o SGP 2 teve uma maior capacidade de redução, reduziu a base para apenas 4.66\% do conjunto de treinamento original.

Apesar de terem um bom desempenho médio nesta base, as duas versões do SGP não são recomendadas em bases desbalanceadas. Em alguns folds, o SGP 1 eve uma taxa de acerto da classe minoritária inferior a 25\%, isso aconteceu porque neste fold, as instâncias não ficaram agrupadas, e foram totalmente eliminadas na aplicação do fator de generalização. O mesmo aconteceu com o SGP 2.

Com este experimento, conclui-se que, em bases altamente desbalanceadas o OSS é muito eficiente e recomendado, assim como o LVQ, isso acontece pelos motivos já citados em sessões anteriores.

O ENN se mostrou altamente ineficiente por remover grande quantidade de instâncias da classe minoritária, o mesmo aconteceu com o SGP 1 e 2, e, em alguns casos com o Tomek Links.

Uma técnica que se comportou de forma diferente dos experimentos anteriores foi o CNN que se mostrou eficiente. Neste caso, pode-se dizer que as instâncias da classe minoritária estão distribuídas e a maioria das instâncias desta classe foram selecionadas. Ou seja, para o uso do CNN, é importante que a classe minoritária esteja bem distribuída para que mais instâncias desta classe sejam selecionadas.

