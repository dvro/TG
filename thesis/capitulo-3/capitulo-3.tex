% !TEX encoding = ISO-8859-1
\chapter{Análise em Bases Artificiais}
\label{ch:analiseembasesartificiais}

Neste capítulo será analisado o desempenho de cada técnicade seleção de protótipos em bases desbalanceadas artificiais. Além da taxa de acerto, será considerada a quantidade de protótipos gerados por cada técnica e a distribuição destes protótipos.

\section{Bases Artificiais}
\label{sec:basesartificiais}

Para avaliar de forma visual o comportamento de cada algoritmo de seleção de protótipos, foram selecionadas bases artificiais com diferentes níveis de sobrebosição entre a classe marjoritária e a classe minotirária. Também foram selecionados dois diferentes níveis de desbalanceamento, um com aproximadamente 10\% de desbalanceamento e outro com aproximadamente 5\%.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/ORIG_10_0.eps}
\caption{Base Original com 10\% de desbalanceamento e intersecção mínima}
\label{fig:orig1}
\end{figure}

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/ORIG_10_15.eps}
\caption{Base Original com 10\% de desbalanceamento e intersecção máxima}
\label{fig:orig2}
\end{figure}


Nas figuras \ref{fig:orig1} e \ref{fig:orig2} estão demonstrados os níveis de intersecção extremos. No primeiro caso, a classe marjoritária está totalmente separada da classe minoritária. No segundo caso, a classe marjoritária engloba toda a classe minoritária. Além destes dois casos, também serão mostrados níveis intermediários de sobreposição. Com estes diferentes níveis de intersecção, será possível avaliar o comportamento de cada técnica diante de diferentes casos de bases desbalanceadas.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/ORIG_5_0.eps}
\caption{Base Original com 5\% de desbalanceamento e intersecção mínima}
\label{fig:orig3}
\end{figure}

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/ORIG_5_15.eps}
\caption{Base Original com 5\% de desbalanceamento e intersecção máxima}
\label{fig:orig4}
\end{figure}

Nas figuras \ref{fig:orig3} e \ref{fig:orig4} observa-se o mesmo caso, sendo que com um nível maior de desbalanceamento. Tendo as mesmas distribuições e intersecções, mas com níveis de desbalanceamentos diferentes, será possível avaliar a relevância dos níveis de desbalanceamento para cada técnica. 

\section{Análise Individual}

Nesta sessão, cada técnica sera analisada isoladamente. Para exemplificar e demonstrar as falhas de cada técnica, serão utilizadas figuras e tabelas que comprovem o comportamento de cada algoritmo diante de bases desbalanceadas.

Todas as conclusões poderão ser validadas ou mesmo reavaliadas com a aplicação das técnicas de seleção de protótipos em bases reais no próximo capítulo.


\subsection{ENN}
\label{subsec:ennembasesartificiais}

	Conforme dito no capítulo anterior, o ENN é uma técnica que elimina ruídos na fronteira de classificação, mantendo instâncias que apresentam redundância de informação. Na tabela \ref{tab:enn5}, podemos ver a taxa de acerto do ENN em uma base com 10\%, onde o nível de sobreposição varia gradualmente, sendo o último nível o caso onda a classe minoritária está totalmente imersa dentro da classe marjoritária, lembrando que, foi utilizado o próprio treinamento para teste, afim de avaliar a representatividade dos dados em relação a base original.

	Observa-se que a o ENN manteve uma boa taxa de acerto geral, sendo o pior caso com 94.74\%. Porém, vemos que esta taxa diminui conforme o nível de sobreposição aumenta, na mesma proporção em que instâncias são eliminadas. Porém, ao observar a taxa de acerto da classe minoritária, pode-se perceber que o ENN eliminou muito mais instâncias da classe minoritária que da marjoritária.
	Inicialmente o nível de sobreposição das classes é zero, então nenhuma instância é eliminada e a taxa de acerto é mantida. Conforme o nível de sobreposição das classes vai aumentnado, a taxa de acerto da classe minoritária vai decrescendo, chegando até 0\% quando a classe minoritária está totalmente sobreposta. Na tabela \ref{tab:enn10} acontece o mesmo, porém, o decrescimento da taxa de acerto da classe minoritária é menor.


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   97.68\%    &   94.74\%   &   94.74\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   99.00\%    &   98.33\%   &   100.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   74.00\%    &   30.00\%   &   0.00\%   \\
\hline
Tamanho resultante      &   100.00\%   &   100.00\%   &   95.79\%    &   90.53\%   &   90.00\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{ENN com nível de desbalanceamento 5\%}
\label{tab:enn5}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   95.80\%    &   90.00\%   &   90.00\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   97.89\%    &   95.56\%   &   100.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   77.00\%    &   40.00\%   &   0.00\%   \\
\hline
Tamanho resultante      &   100.00\%   &   100.00\%   &   92.00\%    &   82.00\%   &   81.00\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{ENN com nível de desbalanceamento 10\%}
\label{tab:enn10}
\end{table}


Quando não existe sobreposição de classes, o ENN pode ser uma boa opção para remoção de ruídos, porém, quando existe sobreposição, esta técnica pode remover praticamente todas as instâncias da classe minoritária, aumentando o nível de desbalanceamento e deixando o classificador inviável para identificação da classe minoritária.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/ENN_10_15.eps}
\caption{ENN sobre sobre base com total sobreposição de classes e 10\% de desbalanceamento}
\label{fig:enn1015}
\end{figure}

A figura \ref{fig:enn1015} mostra o que aconteceu após a aplicação do ENN. Todas as instâncias da classe minoritária foram removidas, pois foram tratadas como ruídos. Apesar de instâncias da classe marjoritária também serem removidas, quanto maior o nível de desbalanceamento, mais inviável a técnica se torna, pois conforme a sobreposição aumenta, mais instâncias são removidas, e a classe minoritária tende a desaparecer mais rapidamente que a marjoritária.

Assim, tendo como base este experimento, conclui-se que o ENN não é uma técnica eficiente para se utilizar em bases altamente desbalanceadas, pois, quanto maior o nível de desbalanceamento, mais instâncias da classe minoritária serão eliminadas.

Uma possível adaptação do ENN seria remover instâncias apenas da classe marjoritária, com isso, o nível de desbalanceamento seria diminuido e a taxa de acerto da classe minoritária não seria afetada em relação ao KNN sobre toda a base original.


\subsection{CNN}

O CNN, diferentemente do ENN, possui a abordagem de remover instâncias redundantes, e não ruídos. O comportamento esperado é que o CNN remova muitas instâncias da classe marjoritária e poucas instâncias da classe minoritária. Dependendo do nível de sobreposição das classes, porém, o CNN pode gerar diferentes resultados. Para os experimentos abaixo foi utilizado o valor de K = 3, pois com K = 1 a taxa de acerto seria de 100\%.

Observando a tabela \ref{tab:cnn5} percebe-se que o CNN obteve uma boa taxa de acerto total, mesmo no caso de bases desbalanceadas. O CNN também teve um alto nível de redução de instâncias. Quando não houve sobreposição, o CNN reduziu a base para 0.32\% do tamanho original, aumentando para 7.47\% quando com nível máximo de sobreposição.

O resultado da tabela não é uniforme pelo fato de o CNN não ser determinístico, dependendo da ordem em que os dados são apresentados. Porém, pode-se observar que, no geral, o CNN obteve uma boa taxa de acerto para a classe minoritária.

Diminuindo o nível de desbalanceamento (10\%), houve uma melhora na taxa de acerto da classe minoritária em todos os níveis de sobreposição. Isso se deve a quantidade de instâncias adicionadas pelo CNN. Com mais instâncias da classe minoritária, a região delimitada por esta classe é maior, com isso, mais instâncias desta classe são mantidas pelo CNN. Pode-se observar isso na tabela \ref{tab:cnn10}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   94.74\%   &   99.26\%   &   97.47\%    &   94.74\%   &   94.11\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   98.67\%    &   97.56\%   &   95.89\%   \\
\hline
Acerto minoritária      &   0.00\%   &   86.00\%   &   76.00\%    &   44.00\%   &   62.00\%   \\
\hline
Tamanho resultante      &   0.32\%   &   0.63\%   &   4.32\%    &   7.68\%   &   7.47\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{CNN com nível de desbalanceamento 5\%}
\label{tab:cnn5}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   90.00\%   &   99.30\%   &   94.70\%    &   91.00\%   &   90.40\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   99.44\%   &   96.22\%    &   94.44\%   &   95.00\%   \\
\hline
Acerto minoritária      &   0.00\%   &   98.00\%   &   81.00\%    &   60.00\%   &   49.00\%   \\
\hline
Tamanho resultante      &   0.50\%   &   1.20\%   &   7.50\%    &   13.30\%   &   13.90\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{CNN com nível de desbalanceamento 10\%}
\label{tab:cnn10}
\end{table}

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/CNN_5_0.eps}
\caption{CNN sobre sobre base sem sobreposição de classes e 5\% de desbalanceamento}
\label{fig:cnn50}
\end{figure}


Pode-se observar que o CNN reduz muito a base de dados quando não há sobreposição entre as classes, porém, garante que, com K=1, a taxa de acerto sobre o próprio treinamento será de 100\%. Neste experimento, porém, a taxa de acerto foi mínima pois foi utilizado K=3, e o CNN deixou apenas 1 instância da classe minoritária, assim, todas as instâncias desta classe foram classificadas erroneamente. O caso pode ser visto na figura \ref{fig:cnn50}.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/CNN_5_5.eps}
\caption{CNN sobreposição III de classes e 5\% de desbalanceamento}
\label{fig:cnn55}
\end{figure}

Observando a figura \ref{fig:cnn55}, também é possível concluir que o CNN remove instâncias redundantes, então, a região de sobreposição é praticamente mantida. Isso mostra que, o CNN colabora para diminuir o nível de desbalanceamento, principalmente diante de classes sobrepostas. Todavia, em casos onde é importante identificar a classe minoritária, é necessário utilizar uma técnica de pré-processamento para melhor delimitar esta classe na região.


\subsection{Tomek Links}

O Tomek Links é uma técnica de seleção de protótipos determinística que atua na região de fronteira. Esta técnica é muito utilizada como pré-processamento de dados, visto que ela remove instâncias que podem ser tratadas como ruídos, mas não tem alto nível de redução de instâncias.

Observando a tabela \ref{tab:tl5}, percebe-se que o Tomek Links não reduziu a base de dados quando não há sobreposição de classes, assim, a taxa de acerto é a máxima. Porém, conforme a região de sobreposição aumenta, mais instâncias são removidas, e com isso, a taxa de acerto começa a ser afetada.

Esta técnica possui uma boa taxa de acerto média, mas, conforme o nível de sobreposição aumenta, menor fica a taxa de acerto da classe minoritária. Isso acontece porque com a eliminação de um Tomek Link o nível de desbalanceamento aumenta, dificultando a classficação correta da classe minoritária.

A tabela \ref{tab:tl10} mostra que, com o mesmo nível de desbalanceamento, quando menor o nível de desbalanceamento (quanto mais instâncias da classe minoritária) mais Tomek Links são feitos, e mais instâncias são removidas. Assim, existe uma redução maior da base de dados.

Com um nível de desbalanceamento menor, mais instâncias da classe minoritária são mantidas em regiões onde não há sobreposição.

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   98.42\%    &   97.47\%   &   97.05\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   99.33\%    &   98.67\%   &   99.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   82.00\%    &   76.00\%   &   62.00\%   \\
\hline
Tamanho resultante      &   100.00\%   &   100.00\%   &   96.84\%    &   94.32\%   &   94.32\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{Tomek Links com nível de desbalanceamento 5\%}
\label{tab:tl5}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   97.30\%    &   94.60\%   &   93.90\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   98.56\%    &   97.00\%   &   97.56\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   86.00\%    &   73.00\%   &   61.00\%   \\
\hline
Tamanho resultante      &   100.00\%   &   100.00\%   &   94.60\%    &   89.60\%   &   89.60\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{Tomek Links com nível de desbalanceamento 10\%}
\label{tab:tl10}
\end{table}


\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/TomekLinks_10_5.eps}
\caption{Tomek Links sobreposição III de classes e 10\% de desbalanceamento}
\label{fig:tomeklinks105}
\end{figure}

Na figura \ref{fig:tomeklinks105}, está mostrado o resultado do \textit{Tomek Links} aplicado numa base de dados com 10\% da classe minoritária e 90\% da classe marjoritária. O nível de sobreposição é o nível III, ou seja, a classe minoritária está parcialmente imersa na classe marjoritária. Observando a figura, percebe-se que o \textit{Tomek Links} remove instâncias da região de sobreposição, e mantém instâncias redundantes.

Com isso, conclui-se que o Tomek Links deve ser utilizado como uma técnica de pré-processamento, pois ainda existe muitos dados redundantes, principalmente da classe marjoritária. 

Uma opção é utilizar o Tomek Links alternativo apresentado em Algorithm \ref{alg:tomek_links_for_unbalanced_datasets}, pois com isso, o nível de desbalanceamento seria reduzido. Outra vantagem é que a região de sobreposição seria classificada como da classe minoritária, caso de interesse na maioria das bases de dados.


\subsection{OSS}

Conforme dito anteriormente, o \textit{One-Sided Selection} é uma técnica muito utilizada como pré-processamento e é apropriada para bases desbalanceadas. Inicialmente, com a aplicação do CNN adaptado para bases desbalanceadas, instâncias redundantes da classe marjoritária são removidas. Depois, com a aplicação do Tomek Links adaptado para bases desbalanceadas, as instâncias da classe marjoritária que estão na fronteira são removidas.

O OSS mantém as instâncias da classe minoritária, e com isso ele favorece a identificação desta classe. Observando a tabela \ref{tab:oss5}, observa-se que a taxa de acerto total é alta, tendo 93.89\% no pior caso, e isso independe do nível de intersecção. Para a classe minoritária, vê-se que a taxa de acerto foi alta, especialmente quando existe um baixo nível de sobreposição de classes.

O poder de redução do OSS também é alto, indo para 9.68\% da base original no pior caso de redução. Neste mesmo caso, o nível de desbalanceamento é reduzido, chegando a ter praticamente a mesma quantidade de instâncias em cada classe.

Observando a tabela \ref{tab:oss10}, percebe-se que com a diminuição do nível de desbalanceamento para 10\% não houve ganho de desepenho nem de redução. Com isso, conclui-se que o OSS é uma técnica eficiente independentemente do nível de desbalanceamento da base.


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   98.74\%   &   99.58\%   &   97.05\%    &   93.37\%   &   93.89\%   \\
\hline
Acerto marjoritária     &   98.67\%   &   99.56\%   &   97.11\%    &   93.44\%   &   94.22\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   96.00\%    &   92.00\%   &   88.00\%   \\
\hline
Tamanho resultante      &   5.58\%   &   5.89\%   &   7.16\%    &   8.63\%   &   9.68\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{OSS com nível de desbalanceamento 5\%}
\label{tab:oss5}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   97.50\%   &   98.80\%   &   95.20\%    &   85.90\%   &   87.50\%   \\
\hline
Acerto marjoritária     &   97.22\%   &   98.67\%   &   95.22\%    &   85.78\%   &   88.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   95.00\%    &   87.00\%   &   83.00\%   \\
\hline
Tamanho resultante      &   10.40\%   &   11.10\%   &   13.60\%    &   15.50\%   &   17.40\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{OSS com nível de desbalanceamento 10\%}
\label{tab:oss10}
\end{table}


\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/OSS_5_5.eps}
\caption{OSS com sobreposição III de classes e 5\% de desbalanceamento}
\label{fig:oss55}
\end{figure}

A figura \ref{fig:oss55} exemplifica a aplicação do \textit{One-Sided Selection} sobre uma base de dados onde a classe minoritária possui apenas 5\% das instâncias e metade das instâncias desta classe estão na região de indecisão. Observa-se que as instâncias da classe marjoritária redudantes foram eliminadas, o que aumenta a capacidade de generalização dos protótipos. Outro detalhe perceptível é que a região de indecisão é tomada pela classe minoritária.

Por estas caracterísitcas, o OSS é uma técnica muito apropriada para bases desbalanceadas, além de ser eficiente no que se refere a redução de instâncias. Porém, uma desvantagem é que a classe minoritária fica com instâncias redudantes após a aplicação, por isso, o OSS é muito utilizado como técnica de pré-processamento de dados para outras técnicas de seleção de protótipos.

\subsection{LVQ}

O \textit{Learning Vector Quantization} é uma técnica seletiva de seleção de protótipos. Diferentemente das técnicas examinadas nas subsessões anteriores, esta é uma técnica seletiva, ou seja, ela cria novas instâncias a partir do conjunto de treinamento.

Para os experimentos das versões do LVQ, foram utilizados 1000 iterações, $\alpha(t)= 0.02 \times e^{(-t/200)}$, sendo $t$ o número da iteração, $w = 0.70$ e $\epsilon = 0.30$. Os protótipos iniciais utilizados foram 5 protótipos para cada classe, sendo eles próximos da mediana da classe correspondente.


\subsubsection{LVQ 1}

O LVQ 1 obteve uma boa taxa de acerto geral, sendo sempre acima de 77.68\%. Observa-se também que o taxa de acerto tende a decrescer conforme o nível de sobreposição de classes aumenta. observando a tabela \ref{tab:lvq15}, percebe-se que a taxa de acerto total decresce conforme o nível de sobreposição aumenta por conta da classe marjoritária, enquanto a classe minoritária se manteve com alto nível de acerto (neste experimento 100\%).

A taxa de acerto da classe minoritária é alta porque as instâncias desta classe estão muito próximas, então, durante o ajuste de protótipos, os mesmos ficam bem ajustados, em posições estratégicas. 

A figura \ref{fig:lvq155} mostra que, em baixo nível de sobreposição, os protótipos ficam em torno do centróide, e o seu espalhamento depende totalmente do nível de espalhamento das classes. Já a figura \ref{fig:lvq1515} mostra que o mesmo acontece, porém, o LVQ 1 tende a dividir as classes. Neste caso, os protótipos da classe marjoritária ficaram mais espalhados, porém, afastados da região de indecisão, por isso, a taxa de acerto da classe minoritária é alta.



\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/LVQ1_5_5.eps}
\caption{LVQ 1 com sobreposição de classes III e 5\% de desbalanceamento}
\label{fig:lvq155}
\end{figure}


\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/LVQ1_5_15.eps}
\caption{LVQ 1 com sobreposição de classes V e 5\% de desbalanceamento}
\label{fig:lvq1515}
\end{figure}


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   93.47\%   &   91.79\%   &   84.84\%    &   74.74\%   &   77.68\%   \\
\hline
Acerto marjoritária     &   93.11\%   &   91.33\%   &   84.00\%    &   73.33\%   &   76.44\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   100.00\%    &   100.00\%   &   100.00\%   \\
\hline
Tamanho resultante      &   1.05\%   &   1.05\%   &   1.05\%    &   1.05\%   &   1.05\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{LVQ1 com nível de desbalanceamento 5\%}
\label{tab:lvq15}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   95.30\%   &   87.40\%   &   80.80\%    &   77.00\%   &   71.90\%   \\
\hline
Acerto marjoritária     &   94.78\%   &   86.00\%   &   78.67\%    &   74.44\%   &   68.78\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   100.00\%    &   100.00\%   &   100.00\%   \\
\hline
Tamanho resultante      &   1.00\%   &   1.00\%   &   1.00\%    &   1.00\%   &   1.00\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{LVQ 1 com nível de desbalanceamento 10\%}
\label{tab:lvq110}
\end{table}


Na tabela \ref{tab:lvq110}, a classe minoritária é composta de 10\% das instâncias, mas ainda assim, as características se mantiveram as mesmas, a taxa de acerto da classe minoritária permaneceu alta, enquanto a taxa da classe marjoritária descresceu conforme o nível de sobreposição aumentou. Porém, a figura \ref{fig:lvq11015} mostra que, conforme a quantidade de instâncias da classe minoritária aumenta, mais espalhados ficam os protótipos desta classe, ocasionando numa maior delimitação da região da mesma.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/LVQ1_10_15.eps}
\caption{LVQ 1 com sobreposição de classes V e 10\% de desbalanceamento}
\label{fig:lvq11015}
\end{figure}

O LVQ1 se mostra eficiente para bases desbalanceadas, principalmente no que se refere a classificar bem instâncias da classe minoritária. Uma grande vantege é que a quantidade de protótipos resultante pode ser pré-definida, com isso, o desbalanceamento pode ser reduzido ou até mesmo eliminado. É recomendado também que a quantidade de protótipos seja proporcional ao nível de espalhamento de cada classe, quanto mais espalhada, mais protótipos são necessários para definir a classe.

\subsubsection{LVQ 2.1}

O LVQ 2.1 também teve uma boa taxa de acerto média, e assim como o LVQ 1, teve taxa de acerto máxima para classe minoritária em todos os níveis de sobreposição de classes. Esses dados podem ser observados na tabela \ref{tab:lvq25} e \ref{tab:lvq210}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   90.84\%   &   89.68\%   &   83.89\%    &   80.11\%   &   76.84\%   \\
\hline
Acerto marjoritária     &   90.33\%   &   89.11\%   &   83.00\%    &   79.00\%   &   75.56\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   100.00\%    &   100.00\%   &   100.00\%   \\
\hline
Tamanho resultante      &   1.05\%   &   1.05\%   &   1.05\%    &   1.05\%   &   1.05\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{LVQ 2.1 com nível de desbalanceamento 5\%}
\label{tab:lvq25}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   95.80\%   &   90.40\%   &   81.60\%    &   80.70\%   &   76.20\%   \\
\hline
Acerto marjoritária     &   95.33\%   &   89.33\%   &   79.56\%    &   78.56\%   &   73.56\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   100.00\%    &   100.00\%   &   100.00\%   \\
\hline
Tamanho resultante      &   1.00\%   &   1.00\%   &   1.00\%    &   1.00\%   &   1.00\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{LVQ 2.1 com nível de desbalanceamento 10\%}
\label{tab:lvq210}
\end{table}



Conforme citado anteriormente, o LVQ 2.1 evita uma divergência entre os protótipos, isto pode ser observado em leves diferenças entre a figura \ref{fig:lvq2100} e a figura \ref{fig:lvq1100}. 

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/LVQ2.1_10_0.eps}
\caption{LVQ 2.1 sem sobreposição de classes e 10\% de desbalanceamento}
\label{fig:lvq2100}
\end{figure}

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/LVQ1_10_0.eps}
\caption{LVQ 1 sem sobreposição de classes e 10\% de desbalanceamento}
\label{fig:lvq1100}
\end{figure}

Observa-se que os protótipos do LVQ 2.1 estão levemente menos espalhados que o LVQ 1, isso afeta a taxa de acerto da classe marjoritária (comparar tabela \ref{tab:lvq110} e \ref{tab:lvq210}). Assim, é interessante utilizar o LVQ 2.1 quando se deseja um menor espalhamento das instâncias, normalmente, quando existe uma distribuição uniforme das classes.

\subsubsection{LVQ 3}

O LVQ 3 tem o objetivo de evitar o sobreajuste do LVQ 2.1. Observando as tabelas \ref{tab:lvq35} e \ref{tab:lvq310}, percebe-se que o LVQ 3 manteve em média o mesmo desempenho que o LVQ 2.1, porém, a diferença de desempenho está em bases de baixo nível de sobreposição entre as classes.


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   95.79\%   &   92.32\%   &   83.68\%    &   78.32\%   &   74.53\%   \\
\hline
Acerto marjoritária     &   95.56\%   &   91.89\%   &   82.78\%    &   77.11\%   &   73.11\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   100.00\%    &   100.00\%   &   100.00\%   \\
\hline
Tamanho resultante      &   1.05\%   &   1.05\%   &   1.05\%    &   1.05\%   &   1.05\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{LVQ 3 com nível de desbalanceamento 5\%}
\label{tab:lvq35}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   94.70\%   &   88.10\%   &   89.40\%    &   75.60\%   &   73.50\%   \\
\hline
Acerto marjoritária     &   94.11\%   &   86.78\%   &   88.22\%    &   72.89\%   &   70.56\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   100.00\%    &   100.00\%   &   100.00\%   \\
\hline
Tamanho resultante      &   1.00\%   &   1.00\%   &   1.00\%    &   1.00\%   &   1.00\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{LVQ 3 com nível de desbalanceamento 10\%}
\label{tab:lvq310}
\end{table}


Comparando a figura \ref{fig:lvq3100} com a figura \ref{fig:lvq2100} e a \ref{fig:lvq1100}, observa-se que o LVQ 3 é o meio termo entre o LVQ 1 e o LVQ 2.1. Assim, recomenda-se o uso do LVQ 3 em bases desbalanceadas em casos onde o nível de sobreposição de classes é baixo e deseja-se conter o nível de espalhamento entre as classes.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/LVQ3_10_0.eps}
\caption{LVQ 3 sem sobreposição de classes e 10\% de desbalanceamento}
\label{fig:lvq3100}
\end{figure}

A escolhe da versão do \textit{Learning Vector Quantization} é tão importante quanto a escolha dos parâmetros de forma apropriada. Nestes experimentos foram utilizados os mesmos valores para parâmetros em comum, então, as conclusões se restrigem ao uso de cada uma em bases desbalanceadas, mas, experimentalmente, verifica-se que a escolha adequada de parâmetros é tão importante quanto a escolha da versão do LVQ.


\subsection{SGP 1}

A primeira versão do \textit{Self-Generating Prototypes} é uma técnica de alto poder de redução muito completa para bases com distribuições multi-modais de classes. Porém, após os experimentos realizados, foi possível identificar uma série de falhas nesta técnica.

Conforme citado no capítulo anterior, o SGP possui um fator de generalização. Neste experimento, foi utilizado $R_n = 0.05$ e $R_s = 0.05$, a escolha de valores foi feita de acordo com o proposto em trabalhos relacionados\cite{csp:sgp}.

O poder de redução desta técnica é muito alto, observa-se na tabela \ref{tab:sgp15} que, mesmo em alto nível de sobreposição, a quantidade de protótipos não pasou de 5.68\% da base original no caso de alto nível de desbalanceamento.

O SGP, sem fator de generalização, apresenta uma taxa de 100\% de acerto sobre o conjunto de treinamento\cite{fayed:sgp}. Porém, ao introduzir o fator de generalização o SGP perde esta propriedade. Observando a tabela \ref{tab:sgp15}, percebe-se que, mesmo com fator de generalização, o SGP 1 obteve boas taxas de acerto para baixo nível de sobreposição. Porém, para um alto nível de sobreposição (níveis IV e V), a classe minoritária obteve 0.00\% de taxa de acerto, enquanto que a classe marjoritária obteve 100\%. O mesmo acontece na tabela \ref{tab:sgp110}, porém, este comportamento ocorreu apenas no nível máximo de sobreposição.


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   97.68\%    &   94.74\%   &   94.74\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   98.89\%    &   100.00\%   &   100.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   76.00\%    &   0.00\%   &   0.00\%   \\
\hline
Tamanho resultante      &   0.53\%   &   2.74\%   &   5.26\%    &   5.16\%   &   5.68\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{SGP 1 com nível de desbalanceamento 5\%}
\label{tab:sgp15}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   95.40\%    &   90.70\%   &   90.00\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   97.89\%    &   95.78\%   &   100.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   73.00\%    &   45.00\%   &   0.00\%   \\
\hline
Tamanho resultante      &   0.40\%   &   3.50\%   &   5.80\%    &   8.20\%   &   5.90\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{SGP 1 com nível de desbalanceamento 10\%}
\label{tab:sgp110}
\end{table}


\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/SGP_5_15.eps}
\caption{SGP 1 com total sobreposição de classes e 5\% de desbalanceamento}
\label{fig:sgp1515}
\end{figure}

Observando a figura \ref{fig:sgp1515}, conclui-se que o fator de generalização fez com que todas as instâncias da classe minoritária fossem eliminadas. Em baixo nível de sobreposição isso não acontece pois as instâncias da classe minoritária são representadas por um mesmo protótipo, porém, conforme o nível de sobreposição aumenta, mais protótipos são necessários para representar esta classe, assim, menos instâncias por protótipos. Quando o algoritmo principal termina, o fator de generalização elimina os grupos que possuem menos que $R_s \times S$, sendo $S$ a quantidade de instâncias do maior grupo. Assim, as instâncias vão sendo removidas independentemente de classe.

Observa-se também que, quando o nível de desbalanceamento é mais acentuado, este efeito ocorre mais rapidamente, pois são menos instâncias para dividir entre os protótipos necessários. Assim, em bases desbalanceadas onde a classe minoritária representa 1\%, por exemplo, provavelmente todas as instâncias destas classes seriam eliminadas, independente do nível de sobreposição. Caso não seja utilizado o fator de generalização, estas instâncias são mantidas, porém, o SGP 1 manterá todos os ruídos, levando a erros de classificação.

Esta é uma falha muito grave, porque apesar de ter uma alta taxa de acerto geral e capacidade de redução, o SGP possui péssimas taxas de acerto para a classe minoritária, chegando até a errar em todos os casos.

Uma solução para o SGP é que o fator de generalização seja mantido, porém, com uma alteração. o $R_n$ eliminaria grupos com poucas instâncias dependendo, não da quantidade de instâncias do maior grupo, mas sim, da quantidade de instâncias do maior grupo da mesma classe. Com esta alteração, a classe minoritária não seria extinta e a taxa de acerto da mesma seria beneficiada.

\subsection{SGP 2}

A segunda versão do \textit{Self-Generating Prototypes} apresenta os mesmos defeitos da primeira versão. Porém, ela apresenta algumas caracterísitcas interessantes que serão abordadas.

Observando as tabelas \ref{tab:sgp25} e \ref{tab:sgp210}, percebe-se que o SGP 2 obteve uma excelente taxa de acerto geral, porém, a taxa de acerto da classe minoritária é altamente prejudicada no momento da generalização. As possíveis adaptações para este problema já foram citados na sub-sessão anterior.

Quanto a quantidade de protótipos, observase que o SGP 2 tem um poder de redução muito maior que o SGP 1, isso acontece devido ao acrescimo do \textit{Pruning} e \textit{Merge}. Em geral o SGP 2 obteve uma taxa de acerto semelhante ao SGP 1, porém, em geral apenas metade dos protótipos foram necessários.


\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   97.58\%    &   94.74\%   &   94.74\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   98.78\%    &   100.00\%   &   100.00\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   76.00\%    &   0.00\%   &   0.00\%   \\
\hline
Tamanho resultante      &   0.21\%   &   1.26\%   &   2.42\%    &   2.63\%   &   2.63\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{SGP 2 com nível de desbalanceamento 5\%}
\label{tab:sgp25}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Nível de Intersecção    &   I   &   II  &   III &   IV  &   V   \\
\hline %----- linha horizontal
Acerto total            &   100.00\%   &   100.00\%   &   95.50\%    &   90.00\%   &   90.20\%   \\
\hline
Acerto marjoritária     &   100.00\%   &   100.00\%   &   98.22\%    &   100.00\%   &   95.56\%   \\
\hline
Acerto minoritária      &   100.00\%   &   100.00\%   &   71.00\%    &   0.00\%   &   42.00\%   \\
\hline
Tamanho resultante      &   0.30\%   &   1.90\%   &   2.90\%    &   2.70\%   &   4.40\%   \\
\hline
\end{tabular}%--- fechamento do ambiente tabular
\end{center}   %fim da centralização da tabela
\caption{SGP 2 com nível de desbalanceamento 10\%}
\label{tab:sgp210}
\end{table}


Comparando-se a figura \ref{fig:sgp2515} com a figura \ref{fig:sgp1515}, observa-se que o SGP 2 manteve a mesma região representada com uma quantidade menor de instâncias. O $Merge$ é um algoritmo determinístico e muito eficiente, já o $Pruning$ não é determinístico, e é necessário um limite de poda para que não aconteça um sobreajuste.

\begin{figure}[H]
\center
\includegraphics[scale=0.40]{imagens/outputs/SGP2_5_15.eps}
\caption{SGP 2 com total sobreposição de classes e 5\% de desbalanceamento}
\label{fig:sgp2515}
\end{figure}

Conclui-se que o SGP 2 é superior ao SGP 1 no que se refere a generalização e redução de protótipos. Porém, esta técnica apresenta os mesmos defeitos do SGP 1, sendo necessária a mesma adaptação citada anteriormente para que a classe minoritária, comumente o caso de maior interesse, possa ser identificada.

